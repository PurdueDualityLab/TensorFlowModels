# TEAMS (Training ELECTRA Augmented with Multi-word Selection)

**Note:** This project is working in progress and please stay tuned.

TEAMS is a text encoder pre-training method that simultaneously learns a
generator and a discriminator using multi-task learning. We propose a new
pre-training task, multi-word selection, and combine it with previous
pre-training tasks for efficient encoder pre-training. We also develop two
techniques, attention-based task-specific heads and partial layer sharing,
to further improve pre-training effectiveness.


Our academic paper [[1]](#1) which describes TEAMS in detail can be found here:
https://arxiv.org/abs/2106.00139.

## References

<a id="1">[1]</a>
Jiaming Shen, Jialu Liu, Tianqi Liu, Cong Yu and Jiawei Han, "Training ELECTRA
Augmented with Multi-word Selection", Findings of the Association for
Computational Linguistics: ACL 2021.
