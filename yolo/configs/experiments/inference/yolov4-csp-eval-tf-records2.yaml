runtime:
  distribution_strategy: mirrored
  mixed_precision_dtype: float32
  loss_scale: "dynamic"
  num_gpus: 1
task:
  model:
    base: 
      backbone:
        type: 'darknet'
        darknet:
          model_id: 'cspdarknet53'
      decoder:
        version: v4
        type: regular
      darknet_weights_file: 'cache://yolov4.weights'
      darknet_weights_cfg: 'cache://yolov4.cfg'
    num_classes: 80
    subdivisions: 16
    _boxes: ['[12.0, 16.0]', '[19.0, 36.0]', '[40.0, 28.0]', '[36.0, 75.0]', '[76.0,55.0]', '[72.0, 146.0]', '[142.0, 110.0]', '[192.0, 243.0]', '[459.0, 401.0]']
    _input_size: null #[512, 512, 3]
    boxes_per_scale: 3
    max_level: 5
    min_level: 3
    norm_activation:
      activation: mish
      norm_epsilon: 0.001
      norm_momentum: 0.99
      use_sync_bn: true
    decoder_activation: leaky
    filter:
      ignore_thresh:
        '5': 0.7
        '4': 0.7
        '3': 0.7
      loss_type:  
        '5': ciou
        '4': ciou
        '3': ciou
      iou_normalizer: 
        '5': 0.05
        '4': 0.05
        '3': 0.05
      cls_normalizer: 
        '5': 0.5
        '4': 0.5
        '3': 0.5
      obj_normalizer: 
        '5': 0.4
        '4': 1.0
        '3': 4.0
      new_cords:
        '5': true
        '4': true
        '3': true
      objectness_smooth: 
        '5': 1.0
        '4': 1.0
        '3': 1.0
      scale_xy:
        '5': 2.0
        '4': 2.0 
        '3': 2.0
      max_boxes: 200
      use_nms: false
      iou_thresh: 0.2
      pre_nms_points: 500
      nms_thresh: 0.6
      use_reduction_sum: true
  train_data:
    global_batch_size: 64
    dtype: float32
    input_path: 'gs://tensorflow2/coco_records/train/2017*'
    is_training: true
    shuffle_buffer_size: 10000
    drop_remainder: true
    parser:
      image_w: 512
      image_h: 512
      min_process_size: 512
      jitter_im: 0.3
      jitter_boxes: 0.4
      aug_rand_zoom: 0.5
      aug_rand_angle: 0.0
      aug_rand_hue: 0.1
      aug_rand_saturation: 1.5
      aug_rand_brightness: 1.5
      aug_rand_translate: 0.20
      max_num_instances: 200
      random_flip: True
      use_tie_breaker: True
      use_scale_xy: true
      letter_box: false
      mosaic: 
        mosaic_frequency: 0.85
        random_crop: True
        crop_area_mosaic: [0.25, 1.0]
        random_crop_mosaic: False
        crop_area_mosaic: [0.25, 0.75]
  validation_data:
    global_batch_size: 8
    dtype: float32
    input_path: 'gs://tensorflow2/coco_records/val/2017*'
    is_training: false
    shuffle_buffer_size: 10000
    drop_remainder: true
    parser:
      image_w: 608
      image_h: 608
      fixed_size: True
      letter_box: false
  weight_decay: 0.001
  # init_checkpoint: 'gs://tensorflow2/darknet/cspdarknet53-golden'
  # init_checkpoint_modules: 'backbone'
  annotation_file: null
  gradient_clip_norm: 0.0
  load_darknet_weights: true
  darknet_load_decoder: false
trainer:
  best_checkpoint_eval_metric: str = "AP50"
  best_checkpoint_metric_comp: str = "higher"
  train_steps: 204000 # 160 epochs at 64 batchsize -> 500500 * 64/2
  validation_steps: 625
  steps_per_loop: 20000
  validation_interval: 20000 #00
  summary_interval: 20000
  checkpoint_interval: 20000
  optimizer_config:
    # ema:
    #   average_decay: 0.9998
    # learning_rate:
    #   type: cosine_epoch
    #   cosine_epoch:
    #     initial_learning_rate: 0.001
    #     name: CosineEpoch
    #     alpha: 0.2
    #     steps_per_epoch: 680
    #     decay_steps: 203000
    # optimizer:
    #   type: adam
    #   adam:
    #     beta_1: 0.949
    #     name: adam
    learning_rate:
      type: stepwise
      stepwise:
        boundaries: [162400, 182700]
        name: PiecewiseConstantDecay
        values: [0.0013, 0.00013, 0.000013]
    optimizer:
      type: sgd
      sgd:
        momentum: 0.949
        nesterov: True
        name: SGD
    warmup:
      type: 'polynomial'
      polynomial:
        power: 4
        warmup_steps: 1000 #learning rate rises from 0 to 0.0013 over 1000 steps