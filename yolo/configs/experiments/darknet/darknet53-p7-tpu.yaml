runtime:
  distribution_strategy: 'tpu'
  mixed_precision_dtype: 'bfloat16'
task:
  load_darknet_weights: false
  model:
    num_classes: 1000
    input_size: [256, 256, 3]
    backbone:
      type: 'darknet'
      darknet:
        model_id: 'csp-large'
    norm_activation:
      activation: 'mish'  
      use_sync_bn: true
    min_level: 3
    max_level: 7
    subdivisions: 1
    darknet_weights_file: ''
    darknet_weights_cfg: ''
  losses:
    l2_weight_decay: 0.0005
    one_hot: True
    label_smoothing: 0.1
  train_data:
    tfds_name: imagenet2012
    tfds_split: train
    tfds_data_dir: 'gs://tensorflow2/tensorflow_datasets/downloads/manual'
    #input_path: 'imagenet-2012-tfrecord/train*'
    is_training: true
    global_batch_size: 512 # 128
    drop_remainder: true
    dtype: 'bfloat16'
    parser:
      aug_rand: true
  validation_data:
    tfds_name: imagenet2012
    tfds_split: validation
    tfds_data_dir: 'gs://tensorflow2/tensorflow_datasets/downloads/manual'
    #input_path: 'imagenet-2012-tfrecord/valid*'
    is_training: false
    global_batch_size: 512 # 128
    dtype: 'bfloat16'
    drop_remainder: false
    parser:
      aug_rand: true
trainer:
  train_steps: 300000 # epochs: 120
  validation_steps: 97 # size of validation data
  validation_interval: 2500
  steps_per_loop: 2500
  summary_interval: 2500
  checkpoint_interval: 2500
  optimizer_config:
    optimizer:
      type: 'sgd'
      sgd:
        momentum: 0.9
    learning_rate:
      type: 'polynomial'
      polynomial:
        initial_learning_rate: 0.4
        end_learning_rate: 0.0000
        power: 4.0
        decay_steps: 299750
    warmup:
      type: 'linear'
      linear:
        warmup_steps: 250 #learning rate rises from 0 to 0.1 over 1000 steps
