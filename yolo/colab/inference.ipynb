{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40f9VBOnRWJj"
      },
      "source": [
        "# YOLO in TensorFlow: Inference Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LarZmCip39it"
      },
      "source": [
        "This is a Google Colaboratory notebook file to demonstrate inference using the TensorFlow Model Garden implementation of YOLOv3 on a video stream from your webcam.\n",
        "\n",
        "First, clone the GitHub repo and import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rECnP_DMQnZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a8c90ae-4397-475d-93df-307fb2347a3f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import pathlib\n",
        "import os\n",
        "import time\n",
        "import urllib.request\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"TensorFlowModelGardeners\" in pathlib.Path.cwd().parts:\n",
        "  while \"TensorFlowModelGardeners\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('TensorFlowModelGardeners').exists():\n",
        "  !git clone https://github.com/PurdueCAM2Project/TensorFlowModelGardeners\n",
        "os.chdir('TensorFlowModelGardeners')\n",
        "!git pull\n",
        "!git checkout ec1a525ae65c7c96c65431164a3173ba0103fc7c\n",
        "!pip install -r yolo/requirements.txt\n",
        "\n",
        "from google.colab import output\n",
        "from IPython.display import JSON, HTML\n",
        "\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from official.core import train_utils\n",
        "from yolo import run as yolo_run\n",
        "from yolo.utils.demos import utils as demo_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TensorFlowModelGardeners'...\n",
            "remote: Enumerating objects: 23104, done.\u001b[K\n",
            "remote: Counting objects: 100% (637/637), done.\u001b[K\n",
            "remote: Compressing objects: 100% (424/424), done.\u001b[K\n",
            "remote: Total 23104 (delta 526), reused 305 (delta 213), pack-reused 22467\u001b[K\n",
            "Receiving objects: 100% (23104/23104), 101.06 MiB | 27.70 MiB/s, done.\n",
            "Resolving deltas: 100% (17578/17578), done.\n",
            "Already up to date.\n",
            "Note: checking out 'ec1a525ae65c7c96c65431164a3173ba0103fc7c'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at ec1a525a Add the inference demo back. Yay!\n",
            "Ignoring importlib-resources: markers 'python_version < \"3.7\"' don't match your environment\n",
            "Collecting absl-py==0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/07/f69dd3367368ad69f174bfe426a973651412ec11d48ec05c000f19fe0561/absl_py-0.10.0-py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 26.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 3)) (1.6.3)\n",
            "Collecting attrs==20.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/df/479736ae1ef59842f512548bacefad1abed705e400212acba43f9b0fa556/attrs-20.2.0-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hCollecting cachetools==4.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl\n",
            "Collecting certifi==2020.6.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl (156kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 7)) (3.0.4)\n",
            "Collecting dill==0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/96/518a8ea959a734b70d2e95fef98bcbfdc7adad1c1e5f5dd9148c835205a5/dill-0.3.2.zip (177kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 43.7MB/s \n",
            "\u001b[?25hCollecting future==0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 35.4MB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Collecting google-auth-oauthlib==0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Collecting google-auth==1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/37/a21382309d6cd433d6f002a683bc4f2e27ad912af11d4c4a7bdd6e8d363d/google_auth-1.21.1-py2.py3-none-any.whl (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 13)) (0.2.0)\n",
            "Collecting googleapis-common-protos==1.52.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/74/3956721ea1eb4bcf7502a311fdaa60b85bd751de4e57d1943afe9b334141/googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.5MB/s \n",
            "\u001b[?25hCollecting grpcio==1.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/54/1c8be62beafe7fb1548d2968e518ca040556b46b0275399d4f3186c56d79/grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.3MB/s \n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 17)) (2.10)\n",
            "Collecting importlib-metadata==1.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: keras-preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 20)) (1.1.2)\n",
            "Collecting markdown==3.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.3MB/s \n",
            "\u001b[?25hCollecting more-itertools==8.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/f7/9c33f38577d9fb9b1aa60c0fd9961d09574f5d47d2b830e5183e6adfc8cc/more_itertools-8.5.0-py3-none-any.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 23)) (1.19.5)\n",
            "Requirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 24)) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 25)) (3.3.0)\n",
            "Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 26)) (2.3)\n",
            "Collecting protobuf==3.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/dc/5ba56eab7440c62c5f808b4267e2a1d6c136e90293b43fefb1b493c6d704/protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 28)) (0.2.8)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 29)) (0.4.8)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 30)) (1.3.0)\n",
            "Collecting requests==2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.9MB/s \n",
            "\u001b[?25hCollecting rsa==4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 33)) (1.4.1)\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 34)) (1.15.0)\n",
            "Collecting tensorboard-plugin-wit==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/85/5c5ac0a8c5efdfab916e9c6bc18963f6a6996a8a1e19ec4ad8c9ac9c623c/tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 55.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 36)) (2.5.0)\n",
            "Collecting tensorflow-addons>=0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 38)) (4.0.1)\n",
            "Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 39)) (2.5.0)\n",
            "Collecting tensorflow-metadata==0.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c4/1ff6a8afaac19250780a82bc05907586f6c23f45a5983df8921040e2b04c/tensorflow_metadata-0.24.0-py3-none-any.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 41)) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 42)) (0.12.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 59.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 44)) (1.1.0)\n",
            "Collecting tqdm==4.49.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/d5/f220e0c69b2f346b5649b66abebb391df1a00a59997a7ccf823325bd7a3e/tqdm-4.49.0-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[?25hCollecting typeguard==2.9.1\n",
            "  Downloading https://files.pythonhosted.org/packages/52/33/3755584541a18d954389447bfd5f9cb7fa20dfbf5094829aee4a103e580c/typeguard-2.9.1-py3-none-any.whl\n",
            "Collecting urllib3==1.25.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 48)) (1.0.1)\n",
            "Collecting wheel==0.35.1\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/00/3df031b3ecd5444d572141321537080b40c1c25e1caa3d86cdd12e5e919c/wheel-0.35.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wrapt==1.12.1 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 50)) (1.12.1)\n",
            "Collecting zipp==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 52)) (1.12.8)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 53)) (1.21.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 54)) (1.5.12)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 55)) (4.1.3)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 56)) (1.1.5)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 15.8MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 60)) (0.4.0)\n",
            "Collecting tf_slim>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 62)) (0.29.23)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 63)) (3.2.2)\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 66)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 67)) (7.1.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from -r yolo/requirements.txt (line 68)) (2.0.2)\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 48.5MB/s \n",
            "\u001b[?25hCollecting tflite_support\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/3b/5e0d9cd967aaa564e3c24b86ef2eda0df40b1500949282d952e8e59a0063/tflite_support-0.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.21.1->-r yolo/requirements.txt (line 12)) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3.0->-r yolo/requirements.txt (line 36)) (0.6.1)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=3.2.1->-r yolo/requirements.txt (line 38)) (5.1.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=3.2.1->-r yolo/requirements.txt (line 38)) (0.1.6)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->-r yolo/requirements.txt (line 41)) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->-r yolo/requirements.txt (line 41)) (3.7.4.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->-r yolo/requirements.txt (line 41)) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->-r yolo/requirements.txt (line 52)) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->-r yolo/requirements.txt (line 52)) (1.26.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->-r yolo/requirements.txt (line 52)) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->-r yolo/requirements.txt (line 52)) (3.0.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->-r yolo/requirements.txt (line 53)) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->-r yolo/requirements.txt (line 53)) (0.4.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->-r yolo/requirements.txt (line 54)) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->-r yolo/requirements.txt (line 54)) (5.0.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->-r yolo/requirements.txt (line 56)) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r yolo/requirements.txt (line 63)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r yolo/requirements.txt (line 63)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r yolo/requirements.txt (line 63)) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->-r yolo/requirements.txt (line 70)) (0.22.2.post1)\n",
            "Collecting pybind11>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/43/7339dbabbc2793718d59703aace4166f53c29ee1c202f6ff5bf8a26c4d91/pybind11-2.6.2-py2.py3-none-any.whl (191kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->-r yolo/requirements.txt (line 52)) (20.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->-r yolo/requirements.txt (line 54)) (1.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r yolo/requirements.txt (line 70)) (1.0.1)\n",
            "Building wheels for collected packages: dill, future, py-cpuinfo, seqeval\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.2-cp37-none-any.whl size=78927 sha256=8d9576712d7c4e0cc887ae471499107c4cef6289a2f58f9c942b2516169f9074\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/4b/a2/34ccdcc2f158742cfe9650675560dea85f78c3f4628f7daad0\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=631e8b28a193b8a7933b189bcdfa346edf011475ce4f6aaf75166f9716843617\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22258 sha256=b15aba0d4cf7f86e74014d32d519f7c2346f2aafa9ad193015332a60fe995e59\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=b209dd66b5e5ec2766638cd122e5085fb66aa81db8f416364e6d31a2f4843eda\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built dill future py-cpuinfo seqeval\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement gast==0.4.0, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.32.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pymc3 3.11.2 has requirement cachetools>=4.2.1, but you'll have cachetools 4.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: absl-py, attrs, cachetools, certifi, dill, future, gast, rsa, google-auth, google-auth-oauthlib, protobuf, googleapis-common-protos, grpcio, h5py, zipp, importlib-metadata, markdown, more-itertools, urllib3, requests, tensorboard-plugin-wit, typeguard, tensorflow-addons, tensorflow-metadata, tensorflow-model-optimization, tqdm, wheel, py-cpuinfo, dataclasses, tf-slim, pyyaml, seqeval, sentencepiece, pybind11, tflite-support\n",
            "  Found existing installation: absl-py 0.12.0\n",
            "    Uninstalling absl-py-0.12.0:\n",
            "      Successfully uninstalled absl-py-0.12.0\n",
            "  Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Found existing installation: cachetools 4.2.2\n",
            "    Uninstalling cachetools-4.2.2:\n",
            "      Successfully uninstalled cachetools-4.2.2\n",
            "  Found existing installation: certifi 2020.12.5\n",
            "    Uninstalling certifi-2020.12.5:\n",
            "      Successfully uninstalled certifi-2020.12.5\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: rsa 4.7.2\n",
            "    Uninstalling rsa-4.7.2:\n",
            "      Successfully uninstalled rsa-4.7.2\n",
            "  Found existing installation: google-auth 1.30.0\n",
            "    Uninstalling google-auth-1.30.0:\n",
            "      Successfully uninstalled google-auth-1.30.0\n",
            "  Found existing installation: google-auth-oauthlib 0.4.4\n",
            "    Uninstalling google-auth-oauthlib-0.4.4:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.4\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "  Found existing installation: googleapis-common-protos 1.53.0\n",
            "    Uninstalling googleapis-common-protos-1.53.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.53.0\n",
            "  Found existing installation: grpcio 1.34.1\n",
            "    Uninstalling grpcio-1.34.1:\n",
            "      Successfully uninstalled grpcio-1.34.1\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: zipp 3.4.1\n",
            "    Uninstalling zipp-3.4.1:\n",
            "      Successfully uninstalled zipp-3.4.1\n",
            "  Found existing installation: importlib-metadata 4.0.1\n",
            "    Uninstalling importlib-metadata-4.0.1:\n",
            "      Successfully uninstalled importlib-metadata-4.0.1\n",
            "  Found existing installation: Markdown 3.3.4\n",
            "    Uninstalling Markdown-3.3.4:\n",
            "      Successfully uninstalled Markdown-3.3.4\n",
            "  Found existing installation: more-itertools 8.7.0\n",
            "    Uninstalling more-itertools-8.7.0:\n",
            "      Successfully uninstalled more-itertools-8.7.0\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tensorboard-plugin-wit 1.8.0\n",
            "    Uninstalling tensorboard-plugin-wit-1.8.0:\n",
            "      Successfully uninstalled tensorboard-plugin-wit-1.8.0\n",
            "  Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "  Found existing installation: tensorflow-metadata 1.0.0\n",
            "    Uninstalling tensorflow-metadata-1.0.0:\n",
            "      Successfully uninstalled tensorflow-metadata-1.0.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: wheel 0.36.2\n",
            "    Uninstalling wheel-0.36.2:\n",
            "      Successfully uninstalled wheel-0.36.2\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed absl-py-0.10.0 attrs-20.2.0 cachetools-4.1.1 certifi-2020.6.20 dataclasses-0.6 dill-0.3.2 future-0.18.2 gast-0.3.3 google-auth-1.21.1 google-auth-oauthlib-0.4.1 googleapis-common-protos-1.52.0 grpcio-1.32.0 h5py-2.10.0 importlib-metadata-1.7.0 markdown-3.2.2 more-itertools-8.5.0 protobuf-3.13.0 py-cpuinfo-8.0.0 pybind11-2.6.2 pyyaml-5.4.1 requests-2.24.0 rsa-4.6 sentencepiece-0.1.95 seqeval-1.2.2 tensorboard-plugin-wit-1.7.0 tensorflow-addons-0.13.0 tensorflow-metadata-0.24.0 tensorflow-model-optimization-0.5.0 tf-slim-1.1.0 tflite-support-0.2.0 tqdm-4.49.0 typeguard-2.9.1 urllib3-1.25.10 wheel-0.35.1 zipp-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "!--PREPPING GPU--! \n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rwMRMTs5Fiq"
      },
      "source": [
        "After cloning the repo, build the model and load the Darknet (paper implementation) pretrained weights. This may take time since Colab needs to download the weights.\n",
        "\n",
        "A prediction function for the model is also created. The [`predict`](https://www.tensorflow.org/api_docs/python/tf/keras/Model?hl=en#predict) function is faster for batched inputs (many images being processed at the same time) than it is for single images, like used in this tutorial. It is used for the sake of example here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLqIfPcI5HEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab3e682-d792-46c5-892d-e0b20c444181"
      },
      "source": [
        "# Try out yolov3.yaml and yolov4-tiny-eval.yaml as well for more fun\n",
        "task, model = yolo_run.load_model('yolo_custom', ['yolo/configs/experiments/yolov4-eval.yaml'])\n",
        "model.make_predict_function()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
            "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
            "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:51: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:51: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'num_classes': 80, '_input_size': None, 'min_level': 3, 'max_level': 5, 'boxes_per_scale': 3, 'base': {'type': None}, 'dilate': False, 'filter': {'iou_thresh': 0.2, 'nms_thresh': 0.9, 'ignore_thresh': 0.7, 'loss_type': 'ciou', 'max_boxes': 200, 'anchor_generation_scale': 416, 'use_nms': False, 'iou_normalizer': 0.07, 'cls_normalizer': 1.0, 'obj_normalizer': 1.0}, 'norm_activation': {'activation': 'mish', 'use_sync_bn': False, 'norm_momentum': 0.99, 'norm_epsilon': 0.001}, 'decoder_activation': 'leaky', '_boxes': ['[12.0, 16.0]', '[19.0, 36.0]', '[40.0, 28.0]', '[36.0, 75.0]', '[76.0, 55.0]', '[72.0, 146.0]', '[142.0, 110.0]', '[192.0, 243.0]', '[459.0, 401.0]']}\n",
            "InputSpec(shape=(None, None, None, 3), ndim=4)\n",
            "<tensorflow.python.keras.regularizers.L2 object at 0x7f32866885d0>\n",
            "DarkNet(model_id='cspdarknet53')\n",
            "Model: \"cspdarknet53\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ConvBN_0_0 (ConvBN)             (None, None, None, 3 992         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_1_csp_down (CSPRoute)   ((None, None, None,  27392       ConvBN_0_0[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_1_0 (DarkResidual)      (None, None, None, 6 20864       DarkRes_1_csp_down[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_1_csp_connect (CSPConne (None, None, None, 6 12800       DarkRes_1_0[0][0]                \n",
            "                                                                 DarkRes_1_csp_down[0][1]         \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_2_csp_down (CSPRoute)   ((None, None, None,  91136       DarkRes_1_csp_connect[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_2_0 (DarkResidual)      (None, None, None, 6 41472       DarkRes_2_csp_down[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_2_1 (DarkResidual)      (None, None, None, 6 41472       DarkRes_2_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_2_csp_connect (CSPConne (None, None, None, 1 21248       DarkRes_2_1[0][0]                \n",
            "                                                                 DarkRes_2_csp_down[0][1]         \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_csp_down (CSPRoute)   ((None, None, None,  362496      DarkRes_2_csp_connect[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_0 (DarkResidual)      (None, None, None, 1 164864      DarkRes_3_csp_down[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_1 (DarkResidual)      (None, None, None, 1 164864      DarkRes_3_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_2 (DarkResidual)      (None, None, None, 1 164864      DarkRes_3_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_3 (DarkResidual)      (None, None, None, 1 164864      DarkRes_3_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_4 (DarkResidual)      (None, None, None, 1 164864      DarkRes_3_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_5 (DarkResidual)      (None, None, None, 1 164864      DarkRes_3_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_6 (DarkResidual)      (None, None, None, 1 164864      DarkRes_3_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_7 (DarkResidual)      (None, None, None, 1 164864      DarkRes_3_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_3_csp_connect (CSPConne (None, None, None, 2 83456       DarkRes_3_7[0][0]                \n",
            "                                                                 DarkRes_3_csp_down[0][1]         \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_csp_down (CSPRoute)   ((None, None, None,  1445888     DarkRes_3_csp_connect[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_0 (DarkResidual)      (None, None, None, 2 657408      DarkRes_4_csp_down[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_1 (DarkResidual)      (None, None, None, 2 657408      DarkRes_4_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_2 (DarkResidual)      (None, None, None, 2 657408      DarkRes_4_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_3 (DarkResidual)      (None, None, None, 2 657408      DarkRes_4_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_4 (DarkResidual)      (None, None, None, 2 657408      DarkRes_4_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_5 (DarkResidual)      (None, None, None, 2 657408      DarkRes_4_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_6 (DarkResidual)      (None, None, None, 2 657408      DarkRes_4_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_7 (DarkResidual)      (None, None, None, 2 657408      DarkRes_4_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_4_csp_connect (CSPConne (None, None, None, 5 330752      DarkRes_4_7[0][0]                \n",
            "                                                                 DarkRes_4_csp_down[0][1]         \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_5_csp_down (CSPRoute)   ((None, None, None,  5775360     DarkRes_4_csp_connect[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_5_0 (DarkResidual)      (None, None, None, 5 2625536     DarkRes_5_csp_down[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_5_1 (DarkResidual)      (None, None, None, 5 2625536     DarkRes_5_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_5_2 (DarkResidual)      (None, None, None, 5 2625536     DarkRes_5_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_5_3 (DarkResidual)      (None, None, None, 5 2625536     DarkRes_5_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DarkRes_5_csp_connect (CSPConne (None, None, None, 1 1316864     DarkRes_5_3[0][0]                \n",
            "                                                                 DarkRes_5_csp_down[0][1]         \n",
            "==================================================================================================\n",
            "Total params: 26,652,512\n",
            "Trainable params: 26,617,184\n",
            "Non-trainable params: 35,328\n",
            "__________________________________________________________________________________________________\n",
            "Downloading data from https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n",
            "16384/12231 [========================================] - 0s 0us/step\n",
            "Downloading data from https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
            "257720320/257717640 [==============================] - 3s 0us/step\n",
            "64 seen\n",
            "major: 0\n",
            "minor: 2\n",
            "revision: 5\n",
            "iseen: 32032000\n",
            "{'_type': 'net', 'batch': 64, 'subdivisions': 8, 'width': 608, 'height': 608, 'channels': 3, 'momentum': 0.949, 'decay': 0.0005, 'angle': 0, 'saturation': 1.5, 'exposure': 1.5, 'hue': 0.1, 'learning_rate': 0.0013, 'burn_in': 1000, 'max_batches': 500500, 'policy': 'steps', 'steps': (400000, 450000), 'scales': (0.1, 0.1), 'mosaic': 1}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 32, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': -2}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 32, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': (-1, -7)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': -2}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': (-1, -10)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': -2}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': (-1, -28)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': -2}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': (-1, -28)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 1024, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': -2}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'route', 'layers': (-1, -16)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 1024, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 1024, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'maxpool', 'stride': 1, 'size': 5}\n",
            "{'_type': 'route', 'layers': -2}\n",
            "{'_type': 'maxpool', 'stride': 1, 'size': 9}\n",
            "{'_type': 'route', 'layers': -4}\n",
            "{'_type': 'maxpool', 'stride': 1, 'size': 13}\n",
            "{'_type': 'route', 'layers': (-1, -3, -5, -6)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 1024, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'upsample', 'stride': 2}\n",
            "{'_type': 'route', 'layers': 85}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'route', 'layers': (-1, -3)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'upsample', 'stride': 2}\n",
            "{'_type': 'route', 'layers': 54}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'route', 'layers': (-1, -3)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 256, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 256, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 256, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'size': 1, 'stride': 1, 'pad': 1, 'filters': 255, 'activation': 'linear'}\n",
            "{'_type': 'yolo', 'mask': (0, 1, 2), 'anchors': [(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], 'classes': 80, 'num': 9, 'jitter': 0.3, 'ignore_thresh': 0.7, 'truth_thresh': 1, 'scale_x_y': 1.2, 'iou_thresh': 0.213, 'cls_normalizer': 1.0, 'iou_normalizer': 0.07, 'iou_loss': 'ciou', 'nms_kind': 'greedynms', 'beta_nms': 0.6, 'max_delta': 5}\n",
            "{'_type': 'route', 'layers': -4}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 2, 'pad': 1, 'filters': 256, 'activation': 'leaky'}\n",
            "{'_type': 'route', 'layers': (-1, -16)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'size': 1, 'stride': 1, 'pad': 1, 'filters': 255, 'activation': 'linear'}\n",
            "{'_type': 'yolo', 'mask': (3, 4, 5), 'anchors': [(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], 'classes': 80, 'num': 9, 'jitter': 0.3, 'ignore_thresh': 0.7, 'truth_thresh': 1, 'scale_x_y': 1.1, 'iou_thresh': 0.213, 'cls_normalizer': 1.0, 'iou_normalizer': 0.07, 'iou_loss': 'ciou', 'nms_kind': 'greedynms', 'beta_nms': 0.6, 'max_delta': 5}\n",
            "{'_type': 'route', 'layers': -4}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 2, 'pad': 1, 'filters': 512, 'activation': 'leaky'}\n",
            "{'_type': 'route', 'layers': (-1, -37)}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 1024, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 1024, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 1024, 'activation': 'leaky'}\n",
            "{'_type': 'convolutional', 'size': 1, 'stride': 1, 'pad': 1, 'filters': 255, 'activation': 'linear'}\n",
            "{'_type': 'yolo', 'mask': (6, 7, 8), 'anchors': [(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], 'classes': 80, 'num': 9, 'jitter': 0.3, 'ignore_thresh': 0.7, 'truth_thresh': 1, 'random': 1, 'scale_x_y': 1.05, 'iou_thresh': 0.213, 'cls_normalizer': 1.0, 'iou_normalizer': 0.07, 'iou_loss': 'ciou', 'nms_kind': 'greedynms', 'beta_nms': 0.6, 'max_delta': 5}\n",
            "full net: \n",
            "608 608 3\tconvCFG(_type='convolutional', w=608, h=608, c=3, size=3, stride=1, pad=1, filters=32)\n",
            "608 608 32\tconvCFG(_type='convolutional', w=608, h=608, c=32, size=3, stride=2, pad=1, filters=64)\n",
            "304 304 64\tconvCFG(_type='convolutional', w=304, h=304, c=64, size=1, stride=1, pad=0, filters=64)\n",
            "304 304 64\trouteCFG(_type='route', w=304, h=304, c=64, layers=(-2,))\n",
            "304 304 64\tconvCFG(_type='convolutional', w=304, h=304, c=64, size=1, stride=1, pad=0, filters=64)\n",
            "304 304 64\tconvCFG(_type='convolutional', w=304, h=304, c=64, size=1, stride=1, pad=0, filters=32)\n",
            "304 304 32\tconvCFG(_type='convolutional', w=304, h=304, c=32, size=3, stride=1, pad=1, filters=64)\n",
            "304 304 64\tshortcutCFG(_type='shortcut', w=304, h=304, c=64, _from=(-3,), activation='linear')\n",
            "304 304 64\tconvCFG(_type='convolutional', w=304, h=304, c=64, size=1, stride=1, pad=0, filters=64)\n",
            "304 304 128\trouteCFG(_type='route', w=304, h=304, c=128, layers=(-1, -7))\n",
            "304 304 128\tconvCFG(_type='convolutional', w=304, h=304, c=128, size=1, stride=1, pad=0, filters=64)\n",
            "304 304 64\tconvCFG(_type='convolutional', w=304, h=304, c=64, size=3, stride=2, pad=1, filters=128)\n",
            "152 152 128\tconvCFG(_type='convolutional', w=152, h=152, c=128, size=1, stride=1, pad=0, filters=64)\n",
            "152 152 128\trouteCFG(_type='route', w=152, h=152, c=128, layers=(-2,))\n",
            "152 152 128\tconvCFG(_type='convolutional', w=152, h=152, c=128, size=1, stride=1, pad=0, filters=64)\n",
            "152 152 64\tconvCFG(_type='convolutional', w=152, h=152, c=64, size=1, stride=1, pad=0, filters=64)\n",
            "152 152 64\tconvCFG(_type='convolutional', w=152, h=152, c=64, size=3, stride=1, pad=1, filters=64)\n",
            "152 152 64\tshortcutCFG(_type='shortcut', w=152, h=152, c=64, _from=(-3,), activation='linear')\n",
            "152 152 64\tconvCFG(_type='convolutional', w=152, h=152, c=64, size=1, stride=1, pad=0, filters=64)\n",
            "152 152 64\tconvCFG(_type='convolutional', w=152, h=152, c=64, size=3, stride=1, pad=1, filters=64)\n",
            "152 152 64\tshortcutCFG(_type='shortcut', w=152, h=152, c=64, _from=(-3,), activation='linear')\n",
            "152 152 64\tconvCFG(_type='convolutional', w=152, h=152, c=64, size=1, stride=1, pad=0, filters=64)\n",
            "152 152 128\trouteCFG(_type='route', w=152, h=152, c=128, layers=(-1, -10))\n",
            "152 152 128\tconvCFG(_type='convolutional', w=152, h=152, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "152 152 128\tconvCFG(_type='convolutional', w=152, h=152, c=128, size=3, stride=2, pad=1, filters=256)\n",
            "76 76 256\tconvCFG(_type='convolutional', w=76, h=76, c=256, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 256\trouteCFG(_type='route', w=76, h=76, c=256, layers=(-2,))\n",
            "76 76 256\tconvCFG(_type='convolutional', w=76, h=76, c=256, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=128)\n",
            "76 76 128\tshortcutCFG(_type='shortcut', w=76, h=76, c=128, _from=(-3,), activation='linear')\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=128)\n",
            "76 76 128\tshortcutCFG(_type='shortcut', w=76, h=76, c=128, _from=(-3,), activation='linear')\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=128)\n",
            "76 76 128\tshortcutCFG(_type='shortcut', w=76, h=76, c=128, _from=(-3,), activation='linear')\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=128)\n",
            "76 76 128\tshortcutCFG(_type='shortcut', w=76, h=76, c=128, _from=(-3,), activation='linear')\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=128)\n",
            "76 76 128\tshortcutCFG(_type='shortcut', w=76, h=76, c=128, _from=(-3,), activation='linear')\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=128)\n",
            "76 76 128\tshortcutCFG(_type='shortcut', w=76, h=76, c=128, _from=(-3,), activation='linear')\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=128)\n",
            "76 76 128\tshortcutCFG(_type='shortcut', w=76, h=76, c=128, _from=(-3,), activation='linear')\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=128)\n",
            "76 76 128\tshortcutCFG(_type='shortcut', w=76, h=76, c=128, _from=(-3,), activation='linear')\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 256\trouteCFG(_type='route', w=76, h=76, c=256, layers=(-1, -28))\n",
            "76 76 256\tconvCFG(_type='convolutional', w=76, h=76, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "76 76 256\tconvCFG(_type='convolutional', w=76, h=76, c=256, size=3, stride=2, pad=1, filters=512)\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 512\trouteCFG(_type='route', w=38, h=38, c=512, layers=(-2,))\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=256)\n",
            "38 38 256\tshortcutCFG(_type='shortcut', w=38, h=38, c=256, _from=(-3,), activation='linear')\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=256)\n",
            "38 38 256\tshortcutCFG(_type='shortcut', w=38, h=38, c=256, _from=(-3,), activation='linear')\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=256)\n",
            "38 38 256\tshortcutCFG(_type='shortcut', w=38, h=38, c=256, _from=(-3,), activation='linear')\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=256)\n",
            "38 38 256\tshortcutCFG(_type='shortcut', w=38, h=38, c=256, _from=(-3,), activation='linear')\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=256)\n",
            "38 38 256\tshortcutCFG(_type='shortcut', w=38, h=38, c=256, _from=(-3,), activation='linear')\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=256)\n",
            "38 38 256\tshortcutCFG(_type='shortcut', w=38, h=38, c=256, _from=(-3,), activation='linear')\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=256)\n",
            "38 38 256\tshortcutCFG(_type='shortcut', w=38, h=38, c=256, _from=(-3,), activation='linear')\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=256)\n",
            "38 38 256\tshortcutCFG(_type='shortcut', w=38, h=38, c=256, _from=(-3,), activation='linear')\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 512\trouteCFG(_type='route', w=38, h=38, c=512, layers=(-1, -28))\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=512)\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=3, stride=2, pad=1, filters=1024)\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 1024\trouteCFG(_type='route', w=19, h=19, c=1024, layers=(-2,))\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=3, stride=1, pad=1, filters=512)\n",
            "19 19 512\tshortcutCFG(_type='shortcut', w=19, h=19, c=512, _from=(-3,), activation='linear')\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=3, stride=1, pad=1, filters=512)\n",
            "19 19 512\tshortcutCFG(_type='shortcut', w=19, h=19, c=512, _from=(-3,), activation='linear')\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=3, stride=1, pad=1, filters=512)\n",
            "19 19 512\tshortcutCFG(_type='shortcut', w=19, h=19, c=512, _from=(-3,), activation='linear')\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=3, stride=1, pad=1, filters=512)\n",
            "19 19 512\tshortcutCFG(_type='shortcut', w=19, h=19, c=512, _from=(-3,), activation='linear')\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 1024\trouteCFG(_type='route', w=19, h=19, c=1024, layers=(-1, -16))\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=1024)\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=3, stride=1, pad=1, filters=1024)\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tmaxpoolCFG(_type='maxpool', w=19, h=19, c=512, stride=1, size=5)\n",
            "19 19 512\trouteCFG(_type='route', w=19, h=19, c=512, layers=(-2,))\n",
            "19 19 512\tmaxpoolCFG(_type='maxpool', w=19, h=19, c=512, stride=1, size=9)\n",
            "19 19 512\trouteCFG(_type='route', w=19, h=19, c=512, layers=(-4,))\n",
            "19 19 512\tmaxpoolCFG(_type='maxpool', w=19, h=19, c=512, stride=1, size=13)\n",
            "19 19 2048\trouteCFG(_type='route', w=19, h=19, c=2048, layers=(-1, -3, -5, -6))\n",
            "19 19 2048\tconvCFG(_type='convolutional', w=19, h=19, c=2048, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=3, stride=1, pad=1, filters=1024)\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "19 19 256\tupsampleCFG(_type='upsample', w=19, h=19, c=256, stride=2)\n",
            "38 38 512\trouteCFG(_type='route', w=38, h=38, c=512, layers=(85,))\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 512\trouteCFG(_type='route', w=38, h=38, c=512, layers=(-1, -3))\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=512)\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=512)\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=1, stride=1, pad=0, filters=128)\n",
            "38 38 128\tupsampleCFG(_type='upsample', w=38, h=38, c=128, stride=2)\n",
            "76 76 256\trouteCFG(_type='route', w=76, h=76, c=256, layers=(54,))\n",
            "76 76 256\tconvCFG(_type='convolutional', w=76, h=76, c=256, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 256\trouteCFG(_type='route', w=76, h=76, c=256, layers=(-1, -3))\n",
            "76 76 256\tconvCFG(_type='convolutional', w=76, h=76, c=256, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=256)\n",
            "76 76 256\tconvCFG(_type='convolutional', w=76, h=76, c=256, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=256)\n",
            "76 76 256\tconvCFG(_type='convolutional', w=76, h=76, c=256, size=1, stride=1, pad=0, filters=128)\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=1, pad=1, filters=256)\n",
            "76 76 256\tconvCFG(_type='convolutional', w=76, h=76, c=256, size=1, stride=1, pad=0, filters=255)\n",
            "76 76 255\tyoloCFG(_type='yolo', w=76, h=76, c=255, mask=(0, 1, 2), anchors=[(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], scale_x_y=1)\n",
            "76 76 128\trouteCFG(_type='route', w=76, h=76, c=128, layers=(-4,))\n",
            "76 76 128\tconvCFG(_type='convolutional', w=76, h=76, c=128, size=3, stride=2, pad=1, filters=256)\n",
            "38 38 512\trouteCFG(_type='route', w=38, h=38, c=512, layers=(-1, -16))\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=512)\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=512)\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=256)\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=1, pad=1, filters=512)\n",
            "38 38 512\tconvCFG(_type='convolutional', w=38, h=38, c=512, size=1, stride=1, pad=0, filters=255)\n",
            "38 38 255\tyoloCFG(_type='yolo', w=38, h=38, c=255, mask=(3, 4, 5), anchors=[(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], scale_x_y=1)\n",
            "38 38 256\trouteCFG(_type='route', w=38, h=38, c=256, layers=(-4,))\n",
            "38 38 256\tconvCFG(_type='convolutional', w=38, h=38, c=256, size=3, stride=2, pad=1, filters=512)\n",
            "19 19 1024\trouteCFG(_type='route', w=19, h=19, c=1024, layers=(-1, -37))\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=3, stride=1, pad=1, filters=1024)\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=3, stride=1, pad=1, filters=1024)\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=512)\n",
            "19 19 512\tconvCFG(_type='convolutional', w=19, h=19, c=512, size=3, stride=1, pad=1, filters=1024)\n",
            "19 19 1024\tconvCFG(_type='convolutional', w=19, h=19, c=1024, size=1, stride=1, pad=0, filters=255)\n",
            "19 19 255\tyoloCFG(_type='yolo', w=19, h=19, c=255, mask=(6, 7, 8), anchors=[(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], scale_x_y=1)\n",
            "bytes_read: 257717640, original_size: 257717640, final_position: 257717640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.def_function.Function at 0x7f328668b050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWL8QjTb5HoN"
      },
      "source": [
        "Below is a function to infer the bounding boxes from an online image using the YOLO model. The frontend will pass the image from the webcam to the backend function in Colab by using a URI. When the backend function receives the image, it will decode the image into a Numpy array of integers (0 to 255) with 3 dimensions (width, height, RGB channels). Next, it will use the TensorFlow to normalize the pixels and resize the image. After that, it will use the model to predict the bounding boxes for any objects that may appear in the image. Finally, the bounding box format is converted to a JSON object so it can be returned and shown on the frontend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfXCscqgxqHP"
      },
      "source": [
        "# A OpenCV flag to treat the input image as an RGB image. This flag has a\n",
        "# different name in OpenCV 2 and OpenCV 3, so a condition is needed to work with\n",
        "# both versions.\n",
        "COLOR_IMAGE = cv2.IMREAD_COLOR if int(cv2.__version__.split('.', 1)[0]) >= 3 \\\n",
        "  else cv2.CV_LOAD_IMAGE_COLOR\n",
        "\n",
        "if model.backbone.model_id == 'cspdarknet53':\n",
        "  MODEL_INPUT_RESOLUTION = (608, 608)\n",
        "else:\n",
        "  MODEL_INPUT_RESOLUTION = (416, 416)\n",
        "DEMO_SCREEN_RESOLUTION = (500, 375)\n",
        "\n",
        "def yolo_infer(uri: str) -> JSON:\n",
        "  try:\n",
        "    # Decode the URI to an image\n",
        "    with urllib.request.urlopen(uri) as response:\n",
        "      data = response.read()\n",
        "    img_buf = np.frombuffer(data, np.uint8)\n",
        "    img = cv2.imdecode(img_buf, COLOR_IMAGE)\n",
        "    \n",
        "    # Rescale the image for use with the model\n",
        "    mat = tf.cast(img, tf.float16)\n",
        "    mat /= 255\n",
        "    mat = tf.expand_dims(mat, axis = 0)\n",
        "    mat = tf.image.resize(mat, MODEL_INPUT_RESOLUTION)\n",
        "\n",
        "    # Run the inference\n",
        "    a = time.time()\n",
        "    pred = model.predict(mat)\n",
        "    a = time.time() - a\n",
        "\n",
        "    # Rescale bounding boxes\n",
        "    bboxes, classes = demo_utils.int_scale_boxes(pred['bbox'], pred['classes'],\n",
        "                                                 *DEMO_SCREEN_RESOLUTION)\n",
        "\n",
        "    # Convert the format of the bounding boxes to match the format in the\n",
        "    # HTML document shown below: [x1, x2, y1, y2, c, p]\n",
        "    bboxes = bboxes[0].numpy()\n",
        "    classes = classes[0].numpy()\n",
        "    confidences = pred['confidence'][0]\n",
        "    num_dets = pred['num_dets'][0]\n",
        "    boxes = []\n",
        "    for i, bbox, class_id, confidence in zip(range(num_dets), bboxes, classes,\n",
        "                                             confidences):\n",
        "      boxes.append(list(bbox) + [class_id, confidence])\n",
        "    print('\\r', a, boxes, end='')\n",
        "\n",
        "    # Return control to the client side (JavaScript in the HTML document)\n",
        "    return JSON(boxes)\n",
        "  except Exception as e:\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "output.register_callback('yolo_infer', yolo_infer)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izo0wxEMMX42"
      },
      "source": [
        "Below is a frontend interface to access the webcam, and stream the images to the backend, and display the bounding boxes to the user. The stream uses JPEG compression to speed up the transfer of images to Colab. The `yolo_infer` function that was made earlier is then called on the compressed JPEG image and the resulting bounding boxes are then drawn on the webcam images when they are recieved back from the backend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWcPgacBSlvm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "1e073e1c-3e80-4d4c-daa3-d28f99068790"
      },
      "source": [
        "HTML(filename='utils/demos/colab_templates/inference.html')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<!--\n",
              "  Sources:\n",
              "    https://www.kirupa.com/html5/accessing_your_webcam_in_html5.htm\n",
              "    https://developer.mozilla.org/en-US/docs/Web/Guide/Audio_and_video_manipulation -->\n",
              "\n",
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<meta charset=\"utf-8\">\n",
              "<style>\n",
              "#container {\n",
              "\tmargin: 0px auto;\n",
              "\twidth: 500px;\n",
              "\theight: 375px;\n",
              "\tborder: 10px #333 solid;\n",
              "}\n",
              "#videoElement {\n",
              "\twidth: 500px;\n",
              "\theight: 375px;\n",
              "\tbackground-color: #666;\n",
              "}\n",
              "#my-canvas {\n",
              "\tbackground-color: #666;\n",
              "}\n",
              "</style>\n",
              "</head>\n",
              "\n",
              "<body>\n",
              "<div id=\"container\">\n",
              "  <canvas id=\"my-canvas\" width=\"500\" height=\"375\"></canvas>\n",
              "\t<video autoplay=\"true\" id=\"videoElement\" style=\"visibility:hidden\"></video>\n",
              "</div>\n",
              "\n",
              "<button id=\"toggleWebcam\">Start Webcam</button>\n",
              "\n",
              "<script src=\"https://code.jquery.com/jquery-3.5.1.min.js\" integrity=\"sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=\" crossorigin=\"anonymous\"></script>\n",
              "<script>\n",
              "  // Load COCO class names from the repo and give the classes seemingly random, but distinct, colors\n",
              "  var classes;\n",
              "  var colors = [];\n",
              "  $.ajax({\n",
              "    url: 'https://raw.githubusercontent.com/PurdueCAM2Project/TensorFlowModelGardeners/master/yolo/dataloaders/dataset_specs/coco.names',\n",
              "    success: function(data) {\n",
              "      classes = data.split('\\n');\n",
              "      for (var i = 0; i < classes.length; i++) {\n",
              "        colors.push(\"#\" + Math.round(0x1000000 * (i / classes.length)).toString(16));\n",
              "      }\n",
              "      for (var i = colors.length - 1; i >= 0; i--) {\n",
              "          j = Math.floor(Math.random() * (i + 1));\n",
              "          x = colors[i];\n",
              "          colors[i] = colors[j];\n",
              "          colors[j] = x;\n",
              "      }\n",
              "    }\n",
              "  });\n",
              "\n",
              "  var video = document.querySelector(\"#videoElement\");\n",
              "  var toggleWebcamButton = document.querySelector(\"#toggleWebcam\");\n",
              "  var camOn = false;\n",
              "\n",
              "  function startWebcam(e) {\n",
              "    camOn = true;\n",
              "    if (navigator.mediaDevices.getUserMedia) {\n",
              "      navigator.mediaDevices.getUserMedia({ video: true })\n",
              "        .then(function (stream) {\n",
              "          video.srcObject = stream;\n",
              "        })\n",
              "        .catch(function (err0r) {\n",
              "          console.log(\"Something went wrong!\");\n",
              "        });\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function stopWebcam(e) {\n",
              "    var stream = video.srcObject;\n",
              "    var tracks = stream.getTracks();\n",
              "\n",
              "    for (var i = 0; i < tracks.length; i++) {\n",
              "      var track = tracks[i];\n",
              "      track.stop();\n",
              "    }\n",
              "\n",
              "    video.srcObject = null;\n",
              "    camOn = false;\n",
              "  }\n",
              "\n",
              "  function toggleWebcam(e) {\n",
              "    if (camOn) {\n",
              "      stopWebcam(e);\n",
              "      toggleWebcamButton.innerText = \"Start Webcam\";\n",
              "    } else {\n",
              "      startWebcam(e);\n",
              "      toggleWebcamButton.innerText = \"Stop Webcam\";\n",
              "      processor.doLoad();\n",
              "    }\n",
              "  }\n",
              "\n",
              "  toggleWebcamButton.addEventListener(\"click\", toggleWebcam);\n",
              "\n",
              "  var processor = {\n",
              "    timerCallback: async function() {\n",
              "      if (!camOn) {\n",
              "        return;\n",
              "      }\n",
              "      await this.computeFrame();\n",
              "      var self = this;\n",
              "      setTimeout(function () {\n",
              "        self.timerCallback();\n",
              "      }, 0);\n",
              "    },\n",
              "\n",
              "    doLoad: function() {\n",
              "      this.video = document.getElementById(\"videoElement\");\n",
              "      this.c1 = document.getElementById(\"my-canvas\");\n",
              "      this.ctx1 = this.c1.getContext(\"2d\");\n",
              "      this.lastFrameBoundingBoxes = [];\n",
              "\n",
              "      this.width = 500;\n",
              "      this.height = 375;\n",
              "      this.timerCallback();\n",
              "    },\n",
              "\n",
              "    computeFrame: async function() {\n",
              "      this.ctx1.drawImage(this.video, 0, 0, this.width, this.height);\n",
              "      var frame = this.ctx1.getImageData(0, 0, this.width, this.height);\n",
              "\n",
              "      this.ctx1.putImageData(frame, 0, 0);\n",
              "      var url = this.c1.toDataURL('image/jpeg', 0.8);\n",
              "      this.drawBoundingBoxes(this.lastFrameBoundingBoxes);\n",
              "      var result = await google.colab.kernel.invokeFunction('yolo_infer', [url], {});\n",
              "      this.lastFrameBoundingBoxes = result.data['application/json'];\n",
              "      return;\n",
              "    },\n",
              "\n",
              "    drawBoundingBoxes: function(boxes) {\n",
              "      for (var i = 0; i < boxes.length; i++) {\n",
              "        const [x1, x2, y1, y2, c, p] = boxes[i];\n",
              "        console.log([classes[c] + \", \" + p, x1, y1]);\n",
              "        debugger;\n",
              "        this.ctx1.beginPath();\n",
              "        this.ctx1.lineWidth = \"2\";\n",
              "        this.ctx1.strokeStyle = colors[c];\n",
              "        this.ctx1.rect(x1, y1, x2-x1, y2-y1);\n",
              "        this.ctx1.stroke();\n",
              "        this.ctx1.font = \"18px Monospace\";\n",
              "        this.ctx1.fillStyle = colors[c];\n",
              "        this.ctx1.fillText(classes[c] + \", \" + p.toFixed(2), x1, y1 - 3);\n",
              "      }\n",
              "    }\n",
              "  };\n",
              "</script>\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "stream",
          "text": [
            " 0.17298340797424316 [[45, 459, 79, 373, 15, 0.4788]]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
