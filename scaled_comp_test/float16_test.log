2021-07-16 22:30:44.757901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-07-16 22:30:45.756969: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-07-16 22:30:45.757635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-07-16 22:30:45.792089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5
coreClock: 1.77GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2021-07-16 22:30:45.792129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-07-16 22:30:45.794413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-07-16 22:30:45.794518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-07-16 22:30:45.795477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-07-16 22:30:45.795772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-07-16 22:30:45.798209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-07-16 22:30:45.798816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-07-16 22:30:45.798965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-07-16 22:30:45.799981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-07-16 22:30:45.800363: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-16 22:30:45.801153: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-07-16 22:30:45.801657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5
coreClock: 1.77GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2021-07-16 22:30:45.801682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-07-16 22:30:45.801703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-07-16 22:30:45.801714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-07-16 22:30:45.801725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-07-16 22:30:45.801735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-07-16 22:30:45.801745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-07-16 22:30:45.801755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-07-16 22:30:45.801765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-07-16 22:30:45.802657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-07-16 22:30:45.802692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-07-16 22:30:46.178637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-16 22:30:46.178676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-07-16 22:30:46.178683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-07-16 22:30:46.180227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6972 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:65:00.0, compute capability: 7.5)
I0716 22:30:46.846658 139826756593472 train_utils.py:285] Final experiment parameters: {'runtime': {'all_reduce_alg': None,
             'batchnorm_spatial_persistent': False,
             'dataset_num_private_threads': None,
             'default_shard_dim': -1,
             'distribution_strategy': 'mirrored',
             'enable_xla': False,
             'gpu_thread_mode': None,
             'loss_scale': 'dynamic',
             'mixed_precision_dtype': 'float16',
             'num_cores_per_replica': 1,
             'num_gpus': 1,
             'num_packs': 1,
             'per_gpu_thread_count': 0,
             'run_eagerly': False,
             'task_index': -1,
             'tpu': None,
             'worker_hosts': None},
 'task': {'annotation_file': None,
          'darknet_load_decoder': True,
          'gradient_clip_norm': 0.0,
          'init_checkpoint': '',
          'init_checkpoint_modules': None,
          'load_darknet_weights': True,
          'model': {'base': {'type': None},
                    'boxes': ['[12.0, 16.0]',
                              '[19.0, 36.0]',
                              '[40.0, 28.0]',
                              '[36.0, 75.0]',
                              '[76.0, 55.0]',
                              '[72.0, 146.0]',
                              '[142.0, 110.0]',
                              '[192.0, 243.0]',
                              '[459.0, 401.0]'],
                    'boxes_per_scale': 3,
                    'filter': {'anchor_generation_scale': 512,
                               'cls_normalizer': {'3': 1.0,
                                                  '4': 1.0,
                                                  '5': 1.0,
                                                  'all': 0.5},
                               'darknet': None,
                               'ignore_thresh': {'3': 0.7,
                                                 '4': 0.7,
                                                 '5': 0.7,
                                                 'all': None},
                               'iou_normalizer': {'3': 0.75,
                                                  '4': 0.75,
                                                  '5': 0.75,
                                                  'all': 0.05},
                               'iou_thresh': 0.001,
                               'label_smoothing': 0.0,
                               'loss_type': {'3': 'ciou',
                                             '4': 'ciou',
                                             '5': 'ciou',
                                             'all': 'ciou'},
                               'max_boxes': 300,
                               'max_delta': {'3': inf,
                                             '4': inf,
                                             '5': inf,
                                             'all': None},
                               'max_level': 5,
                               'min_level': 3,
                               'new_cords': {'3': True,
                                             '4': True,
                                             '5': True,
                                             'all': True},
                               'nms_thresh': 0.6,
                               'nms_type': 'greedy',
                               'obj_normalizer': {'3': 4.0,
                                                  '4': 1.0,
                                                  '5': 0.4,
                                                  'all': None},
                               'objectness_smooth': {'3': 0.0,
                                                     '4': 0.0,
                                                     '5': 0.0,
                                                     'all': 1.0},
                               'path_scales': {'3': 8, '4': 16, '5': 32},
                               'pre_nms_points': 5000,
                               'scale_xy': {'3': 2.0,
                                            '4': 2.0,
                                            '5': 2.0,
                                            'all': 2.0},
                               'truth_thresh': {'3': 1.0,
                                                '4': 1.0,
                                                '5': 1.0,
                                                'all': None},
                               'use_scaled_loss': True},
                    'input_size': [640, 640, 3],
                    'max_level': 5,
                    'min_level': 3,
                    'norm_activation': {'activation': 'mish',
                                        'norm_epsilon': 0.0001,
                                        'norm_momentum': 0.97,
                                        'use_sync_bn': True},
                    'num_classes': 80,
                    'smart_bias': True,
                    'subdivisions': 1},
          'per_category_metrics': False,
          'smart_bias_lr': 0.0,
          'train_data': {'block_length': 1,
                         'cache': False,
                         'cycle_length': None,
                         'decoder': {'simple_decoder': {'regenerate_source_id': False},
                                     'type': 'simple_decoder'},
                         'deterministic': None,
                         'drop_remainder': True,
                         'dtype': 'float32',
                         'enable_tf_data_service': False,
                         'global_batch_size': 1,
                         'input_path': '',
                         'is_training': False,
                         'parser': {'anchor_thresh': 4.0,
                                    'area_thresh': 0.0,
                                    'aug_rand_angle': 0.0,
                                    'aug_rand_brightness': 0.0,
                                    'aug_rand_hue': 0.0,
                                    'aug_rand_saturation': 0.0,
                                    'aug_rand_translate': 0.0,
                                    'aug_scale_max': 0.0,
                                    'aug_scale_min': 0.0,
                                    'jitter': 0.0,
                                    'jitter_mosaic': 0.0,
                                    'letter_box': False,
                                    'max_num_instances': 300,
                                    'mosaic': {'aspect_ratio_mode': 'crop',
                                               'aug_scale_max': None,
                                               'aug_scale_min': None,
                                               'crop_area': [0.25, 1.0],
                                               'crop_area_mosaic': [0.1, 1.9],
                                               'jitter': None,
                                               'max_resolution': None,
                                               'mosaic_crop_mode': 'scale',
                                               'mosaic_frequency': 0.0,
                                               'output_resolution': [640, 640],
                                               'resize': None},
                                    'mosaic_scale_max': 1.0,
                                    'mosaic_scale_min': 1.0,
                                    'mosaic_translate': 0.0,
                                    'random_flip': False,
                                    'random_pad': False,
                                    'resize': 1.0,
                                    'resize_mosaic': 1.0,
                                    'sheer': 0.0,
                                    'use_scale_xy': True,
                                    'use_tie_breaker': True},
                         'seed': None,
                         'sharding': True,
                         'shuffle_buffer_size': 2,
                         'tf_data_service_address': None,
                         'tf_data_service_job_name': None,
                         'tfds_as_supervised': False,
                         'tfds_data_dir': '/media/vbanna/DATA_SHARE/CV/datasets/tensorflow',
                         'tfds_download': True,
                         'tfds_name': 'coco',
                         'tfds_skip_decoding_feature': '',
                         'tfds_split': 'validation'},
          'validation_data': {'block_length': 1,
                              'cache': False,
                              'cycle_length': None,
                              'decoder': {'simple_decoder': {'regenerate_source_id': False},
                                          'type': 'simple_decoder'},
                              'deterministic': None,
                              'drop_remainder': True,
                              'dtype': 'float32',
                              'enable_tf_data_service': False,
                              'global_batch_size': 1,
                              'input_path': '',
                              'is_training': False,
                              'parser': {'anchor_thresh': 4.0,
                                         'area_thresh': 0.0,
                                         'aug_rand_angle': 0.0,
                                         'aug_rand_brightness': 0.0,
                                         'aug_rand_hue': 0.0,
                                         'aug_rand_saturation': 0.0,
                                         'aug_rand_translate': 0.0,
                                         'aug_scale_max': 1.0,
                                         'aug_scale_min': 1.0,
                                         'jitter': 0.0,
                                         'jitter_mosaic': 0.0,
                                         'letter_box': False,
                                         'max_num_instances': 200,
                                         'mosaic': {'aspect_ratio_mode': 'crop',
                                                    'aug_scale_max': None,
                                                    'aug_scale_min': None,
                                                    'crop_area': [0.2, 1.0],
                                                    'crop_area_mosaic': [1.0,
                                                                         1.0],
                                                    'jitter': None,
                                                    'max_resolution': 640,
                                                    'mosaic_crop_mode': 'crop_scale',
                                                    'mosaic_frequency': 0.75,
                                                    'output_resolution': None,
                                                    'resize': None},
                                         'mosaic_scale_max': 1.0,
                                         'mosaic_scale_min': 1.0,
                                         'mosaic_translate': 0.0,
                                         'random_flip': True,
                                         'random_pad': True,
                                         'resize': 1.0,
                                         'resize_mosaic': 1.0,
                                         'sheer': 0.0,
                                         'use_scale_xy': True,
                                         'use_tie_breaker': True},
                              'seed': None,
                              'sharding': True,
                              'shuffle_buffer_size': 2,
                              'tf_data_service_address': None,
                              'tf_data_service_job_name': None,
                              'tfds_as_supervised': False,
                              'tfds_data_dir': '/media/vbanna/DATA_SHARE/CV/datasets/tensorflow',
                              'tfds_download': True,
                              'tfds_name': 'coco',
                              'tfds_skip_decoding_feature': '',
                              'tfds_split': 'validation'},
          'weight_decay': 0.0005},
 'trainer': {'allow_tpu_summary': False,
             'best_checkpoint_eval_metric': '',
             'best_checkpoint_export_subdir': '',
             'best_checkpoint_metric_comp': 'higher',
             'checkpoint_interval': 10000,
             'continuous_eval_timeout': 3600,
             'eval_tf_function': True,
             'eval_tf_while_loop': False,
             'loss_upper_bound': 1000000.0,
             'max_to_keep': 5,
             'optimizer_config': {'ema': None,
                                  'learning_rate': {'cosine': {'alpha': 0.2,
                                                               'decay_steps': 370000,
                                                               'initial_learning_rate': 0.0,
                                                               'name': 'Cosine'},
                                                    'type': 'cosine'},
                                  'optimizer': {'sgd': {'clipnorm': None,
                                                        'clipvalue': None,
                                                        'decay': 0.0,
                                                        'global_clipnorm': None,
                                                        'momentum': 0.937,
                                                        'name': 'SGD',
                                                        'nesterov': True},
                                                'type': 'sgd'},
                                  'type': None,
                                  'warmup': {'linear': {'name': 'linear',
                                                        'warmup_learning_rate': 0,
                                                        'warmup_steps': 0},
                                             'type': 'linear'}},
             'recovery_begin_steps': 0,
             'recovery_max_trials': 0,
             'steps_per_loop': 10000,
             'summary_interval': 10000,
             'train_steps': 100,
             'train_tf_function': True,
             'train_tf_while_loop': True,
             'validation_interval': 20000,
             'validation_steps': 5000}}
I0716 22:30:46.847159 139826756593472 train_utils.py:295] Saving experiment configuration to ../checkpoints/sdsfsfd/params.yaml
2021-07-16 22:30:46.861704: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 2070 SUPER, compute capability 7.5
I0716 22:30:46.862286 139826756593472 device_compatibility_check.py:120] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 2070 SUPER, compute capability 7.5
WARNING:tensorflow:From /home/vbanna/.local/lib/python3.8/site-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale
W0716 22:30:46.862440 139826756593472 deprecation.py:333] From /home/vbanna/.local/lib/python3.8/site-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I0716 22:30:46.865992 139826756593472 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I0716 22:30:46.866652 139826756593472 train_utils.py:214] Running default trainer.
2021-07-16 22:30:46.983537: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.054004 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.054987 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.056380 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.056973 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.058200 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.060388 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.148147 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.148777 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.149659 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0716 22:30:47.150096 139826756593472 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).

!--PREPPING GPU--! 
1 Physical GPUs, 1 Logical GPUs
yolo_custom
{'task': {'init_checkpoint': '', 'model': {'num_classes': 80, 'input_size': [640, 640, 3], 'min_level': 3, 'max_level': 5, 'boxes_per_scale': 3, 'base': {'type': None}, 'subdivisions': 1, 'filter': {'min_level': 3, 'max_level': 5, 'ignore_thresh': {'3': 0.7, '4': 0.7, '5': 0.7, 'all': None}, 'truth_thresh': {'3': 1.0, '4': 1.0, '5': 1.0, 'all': None}, 'loss_type': {'3': 'ciou', '4': 'ciou', '5': 'ciou', 'all': 'ciou'}, 'iou_normalizer': {'3': 0.75, '4': 0.75, '5': 0.75, 'all': 0.05}, 'cls_normalizer': {'3': 1.0, '4': 1.0, '5': 1.0, 'all': 0.5}, 'obj_normalizer': {'3': 4.0, '4': 1.0, '5': 0.4, 'all': None}, 'max_delta': {'3': inf, '4': inf, '5': inf, 'all': None}, 'new_cords': {'3': True, '4': True, '5': True, 'all': True}, 'scale_xy': {'3': 2.0, '4': 2.0, '5': 2.0, 'all': 2.0}, 'path_scales': {'3': 8, '4': 16, '5': 32}, 'objectness_smooth': {'3': 0.0, '4': 0.0, '5': 0.0, 'all': 1.0}, 'nms_type': 'greedy', 'iou_thresh': 0.001, 'nms_thresh': 0.6, 'max_boxes': 300, 'pre_nms_points': 5000, 'label_smoothing': 0.0, 'anchor_generation_scale': 512, 'use_scaled_loss': True, 'darknet': None}, 'norm_activation': {'activation': 'mish', 'use_sync_bn': True, 'norm_momentum': 0.97, 'norm_epsilon': 0.0001}, 'boxes': ['[12.0, 16.0]', '[19.0, 36.0]', '[40.0, 28.0]', '[36.0, 75.0]', '[76.0, 55.0]', '[72.0, 146.0]', '[142.0, 110.0]', '[192.0, 243.0]', '[459.0, 401.0]'], 'smart_bias': True}, 'train_data': {'input_path': '', 'tfds_name': 'coco', 'tfds_split': 'validation', 'global_batch_size': 1, 'is_training': False, 'drop_remainder': True, 'shuffle_buffer_size': 2, 'cache': False, 'cycle_length': None, 'block_length': 1, 'deterministic': None, 'sharding': True, 'enable_tf_data_service': False, 'tf_data_service_address': None, 'tf_data_service_job_name': None, 'tfds_data_dir': '/media/vbanna/DATA_SHARE/CV/datasets/tensorflow', 'tfds_as_supervised': False, 'tfds_skip_decoding_feature': '', 'seed': None, 'dtype': 'float32', 'decoder': {'type': 'simple_decoder', 'simple_decoder': {'regenerate_source_id': False}}, 'parser': {'max_num_instances': 300, 'letter_box': False, 'random_flip': False, 'random_pad': False, 'jitter': 0.0, 'resize': 1.0, 'jitter_mosaic': 0.0, 'resize_mosaic': 1.0, 'sheer': 0.0, 'aug_rand_angle': 0.0, 'aug_rand_saturation': 0.0, 'aug_rand_brightness': 0.0, 'aug_rand_hue': 0.0, 'aug_scale_min': 0.0, 'aug_scale_max': 0.0, 'aug_rand_translate': 0.0, 'mosaic_scale_min': 1.0, 'mosaic_scale_max': 1.0, 'mosaic_translate': 0.0, 'use_tie_breaker': True, 'use_scale_xy': True, 'anchor_thresh': 4.0, 'area_thresh': 0.0, 'mosaic': {'max_resolution': None, 'mosaic_frequency': 0.0, 'crop_area': [0.25, 1.0], 'crop_area_mosaic': [0.1, 1.9], 'aspect_ratio_mode': 'crop', 'mosaic_crop_mode': 'scale', 'aug_scale_min': None, 'aug_scale_max': None, 'jitter': None, 'resize': None, 'output_resolution': [640, 640]}}, 'tfds_download': True}, 'validation_data': {'input_path': '', 'tfds_name': 'coco', 'tfds_split': 'validation', 'global_batch_size': 1, 'is_training': False, 'drop_remainder': True, 'shuffle_buffer_size': 2, 'cache': False, 'cycle_length': None, 'block_length': 1, 'deterministic': None, 'sharding': True, 'enable_tf_data_service': False, 'tf_data_service_address': None, 'tf_data_service_job_name': None, 'tfds_data_dir': '/media/vbanna/DATA_SHARE/CV/datasets/tensorflow', 'tfds_as_supervised': False, 'tfds_skip_decoding_feature': '', 'seed': None, 'dtype': 'float32', 'decoder': {'type': 'simple_decoder', 'simple_decoder': {'regenerate_source_id': False}}, 'parser': {'max_num_instances': 200, 'letter_box': False, 'random_flip': True, 'random_pad': True, 'jitter': 0.0, 'resize': 1.0, 'jitter_mosaic': 0.0, 'resize_mosaic': 1.0, 'sheer': 0.0, 'aug_rand_angle': 0.0, 'aug_rand_saturation': 0.0, 'aug_rand_brightness': 0.0, 'aug_rand_hue': 0.0, 'aug_scale_min': 1.0, 'aug_scale_max': 1.0, 'aug_rand_translate': 0.0, 'mosaic_scale_min': 1.0, 'mosaic_scale_max': 1.0, 'mosaic_translate': 0.0, 'use_tie_breaker': True, 'use_scale_xy': True, 'anchor_thresh': 4.0, 'area_thresh': 0.0, 'mosaic': {'max_resolution': 640, 'mosaic_frequency': 0.75, 'crop_area': [0.2, 1.0], 'crop_area_mosaic': [1.0, 1.0], 'aspect_ratio_mode': 'crop', 'mosaic_crop_mode': 'crop_scale', 'aug_scale_min': None, 'aug_scale_max': None, 'jitter': None, 'resize': None, 'output_resolution': None}}, 'tfds_download': True}, 'weight_decay': 0.0005, 'annotation_file': None, 'gradient_clip_norm': 0.0, 'per_category_metrics': False, 'load_darknet_weights': True, 'darknet_load_decoder': True, 'init_checkpoint_modules': None, 'smart_bias_lr': 0.0}, 'trainer': {'optimizer_config': {'optimizer': {'type': 'sgd', 'sgd': {'clipnorm': None, 'clipvalue': None, 'global_clipnorm': None, 'name': 'SGD', 'decay': 0.0, 'nesterov': True, 'momentum': 0.937}}, 'ema': None, 'learning_rate': {'type': 'cosine', 'cosine': {'name': 'Cosine', 'initial_learning_rate': 0.0, 'decay_steps': 370000, 'alpha': 0.2}}, 'warmup': {'type': 'linear', 'linear': {'name': 'linear', 'warmup_learning_rate': 0, 'warmup_steps': 0}}, 'type': None}, 'train_tf_while_loop': True, 'train_tf_function': True, 'eval_tf_function': True, 'eval_tf_while_loop': False, 'allow_tpu_summary': False, 'steps_per_loop': 10000, 'summary_interval': 10000, 'checkpoint_interval': 10000, 'max_to_keep': 5, 'continuous_eval_timeout': 3600, 'train_steps': 100, 'validation_steps': 5000, 'validation_interval': 20000, 'best_checkpoint_export_subdir': '', 'best_checkpoint_eval_metric': '', 'best_checkpoint_metric_comp': 'higher', 'loss_upper_bound': 1000000.0, 'recovery_begin_steps': 0, 'recovery_max_trials': 0}, 'runtime': {'distribution_strategy': 'mirrored', 'enable_xla': False, 'gpu_thread_mode': None, 'dataset_num_private_threads': None, 'per_gpu_thread_count': 0, 'tpu': None, 'num_gpus': 1, 'worker_hosts': None, 'task_index': -1, 'all_reduce_alg': None, 'num_packs': 1, 'mixed_precision_dtype': 'float16', 'loss_scale': 'dynamic', 'run_eagerly': False, 'batchnorm_spatial_persistent': False, 'num_cores_per_replica': 1, 'default_shard_dim': -1}}
defaultdict(<class 'list'>, {'3': ['box_loss', 'class_loss', 'conf_loss', 'recall50', 'precision50', 'avg_iou', 'avg_obj'], '4': ['box_loss', 'class_loss', 'conf_loss', 'recall50', 'precision50', 'avg_iou', 'avg_obj'], '5': ['box_loss', 'class_loss', 'conf_loss', 'recall50', 'precision50', 'avg_iou', 'avg_obj'], 'global': ['total_loss', 'total_box', 'total_class', 'total_conf']})
[[12.0, 16.0], [19.0, 36.0], [40.0, 28.0], [36.0, 75.0], [76.0, 55.0], [72.0, 146.0], [142.0, 110.0], [192.0, 243.0], [459.0, 401.0]]
{'num_classes': 80, 'input_size': [640, 640, 3], 'min_level': 3, 'max_level': 5, 'boxes_per_scale': 3, 'base': {'type': None}, 'subdivisions': 1, 'filter': {'min_level': 3, 'max_level': 5, 'ignore_thresh': {'3': 0.7, '4': 0.7, '5': 0.7, 'all': None}, 'truth_thresh': {'3': 1.0, '4': 1.0, '5': 1.0, 'all': None}, 'loss_type': {'3': 'ciou', '4': 'ciou', '5': 'ciou', 'all': 'ciou'}, 'iou_normalizer': {'3': 0.75, '4': 0.75, '5': 0.75, 'all': 0.05}, 'cls_normalizer': {'3': 1.0, '4': 1.0, '5': 1.0, 'all': 0.5}, 'obj_normalizer': {'3': 4.0, '4': 1.0, '5': 0.4, 'all': None}, 'max_delta': {'3': inf, '4': inf, '5': inf, 'all': None}, 'new_cords': {'3': True, '4': True, '5': True, 'all': True}, 'scale_xy': {'3': 2.0, '4': 2.0, '5': 2.0, 'all': 2.0}, 'path_scales': {'3': 8, '4': 16, '5': 32}, 'objectness_smooth': {'3': 0.0, '4': 0.0, '5': 0.0, 'all': 1.0}, 'nms_type': 'greedy', 'iou_thresh': 0.001, 'nms_thresh': 0.6, 'max_boxes': 300, 'pre_nms_points': 5000, 'label_smoothing': 0.0, 'anchor_generation_scale': 512, 'use_scaled_loss': True, 'darknet': None}, 'norm_activation': {'activation': 'mish', 'use_sync_bn': True, 'norm_momentum': 0.97, 'norm_epsilon': 0.0001}, 'boxes': ['[12.0, 16.0]', '[19.0, 36.0]', '[40.0, 28.0]', '[36.0, 75.0]', '[76.0, 55.0]', '[72.0, 146.0]', '[142.0, 110.0]', '[192.0, 243.0]', '[459.0, 401.0]'], 'smart_bias': True}
InputSpec(shape=(None, 640, 640, 3), ndim=4)
<tensorflow.python.keras.regularizers.L2 object at 0x7f29ce2bd2e0>
Model: "altered_cspdarknet53"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 640, 640, 3) 0                                            
__________________________________________________________________________________________________
ConvBN_0_0 (ConvBN)             (None, 640, 640, 32) 992         input_1[0][0]                    
__________________________________________________________________________________________________
DarkRes_1_residual_down (DarkRe (None, 320, 320, 64) 39552       ConvBN_0_0[0][0]                 
__________________________________________________________________________________________________
DarkRes_2_csp_down (CSPRoute)   ((None, 160, 160, 64 91136       DarkRes_1_residual_down[0][0]    
__________________________________________________________________________________________________
DarkRes_2_0 (DarkResidual)      (None, 160, 160, 64) 41472       DarkRes_2_csp_down[0][0]         
__________________________________________________________________________________________________
DarkRes_2_1 (DarkResidual)      (None, 160, 160, 64) 41472       DarkRes_2_0[0][0]                
__________________________________________________________________________________________________
DarkRes_2_csp_connect (CSPConne (None, 160, 160, 128 21248       DarkRes_2_1[0][0]                
                                                                 DarkRes_2_csp_down[0][1]         
__________________________________________________________________________________________________
DarkRes_3_csp_down (CSPRoute)   ((None, 80, 80, 128) 362496      DarkRes_2_csp_connect[0][0]      
__________________________________________________________________________________________________
DarkRes_3_0 (DarkResidual)      (None, 80, 80, 128)  164864      DarkRes_3_csp_down[0][0]         
__________________________________________________________________________________________________
DarkRes_3_1 (DarkResidual)      (None, 80, 80, 128)  164864      DarkRes_3_0[0][0]                
__________________________________________________________________________________________________
DarkRes_3_2 (DarkResidual)      (None, 80, 80, 128)  164864      DarkRes_3_1[0][0]                
__________________________________________________________________________________________________
DarkRes_3_3 (DarkResidual)      (None, 80, 80, 128)  164864      DarkRes_3_2[0][0]                
__________________________________________________________________________________________________
DarkRes_3_4 (DarkResidual)      (None, 80, 80, 128)  164864      DarkRes_3_3[0][0]                
__________________________________________________________________________________________________
DarkRes_3_5 (DarkResidual)      (None, 80, 80, 128)  164864      DarkRes_3_4[0][0]                
__________________________________________________________________________________________________
DarkRes_3_6 (DarkResidual)      (None, 80, 80, 128)  164864      DarkRes_3_5[0][0]                
__________________________________________________________________________________________________
DarkRes_3_7 (DarkResidual)      (None, 80, 80, 128)  164864      DarkRes_3_6[0][0]                
__________________________________________________________________________________________________
DarkRes_3_csp_connect (CSPConne (None, 80, 80, 256)  83456       DarkRes_3_7[0][0]                
                                                                 DarkRes_3_csp_down[0][1]         
__________________________________________________________________________________________________
DarkRes_4_csp_down (CSPRoute)   ((None, 40, 40, 256) 1445888     DarkRes_3_csp_connect[0][0]      
__________________________________________________________________________________________________
DarkRes_4_0 (DarkResidual)      (None, 40, 40, 256)  657408      DarkRes_4_csp_down[0][0]         
__________________________________________________________________________________________________
DarkRes_4_1 (DarkResidual)      (None, 40, 40, 256)  657408      DarkRes_4_0[0][0]                
__________________________________________________________________________________________________
DarkRes_4_2 (DarkResidual)      (None, 40, 40, 256)  657408      DarkRes_4_1[0][0]                
__________________________________________________________________________________________________
DarkRes_4_3 (DarkResidual)      (None, 40, 40, 256)  657408      DarkRes_4_2[0][0]                
__________________________________________________________________________________________________
DarkRes_4_4 (DarkResidual)      (None, 40, 40, 256)  657408      DarkRes_4_3[0][0]                
__________________________________________________________________________________________________
DarkRes_4_5 (DarkResidual)      (None, 40, 40, 256)  657408      DarkRes_4_4[0][0]                
__________________________________________________________________________________________________
DarkRes_4_6 (DarkResidual)      (None, 40, 40, 256)  657408      DarkRes_4_5[0][0]                
__________________________________________________________________________________________________
DarkRes_4_7 (DarkResidual)      (None, 40, 40, 256)  657408      DarkRes_4_6[0][0]                
__________________________________________________________________________________________________
DarkRes_4_csp_connect (CSPConne (None, 40, 40, 512)  330752      DarkRes_4_7[0][0]                
                                                                 DarkRes_4_csp_down[0][1]         
__________________________________________________________________________________________________
DarkRes_5_csp_down (CSPRoute)   ((None, 20, 20, 512) 5775360     DarkRes_4_csp_connect[0][0]      
__________________________________________________________________________________________________
DarkRes_5_0 (DarkResidual)      (None, 20, 20, 512)  2625536     DarkRes_5_csp_down[0][0]         
__________________________________________________________________________________________________
DarkRes_5_1 (DarkResidual)      (None, 20, 20, 512)  2625536     DarkRes_5_0[0][0]                
__________________________________________________________________________________________________
DarkRes_5_2 (DarkResidual)      (None, 20, 20, 512)  2625536     DarkRes_5_1[0][0]                
__________________________________________________________________________________________________
DarkRes_5_3 (DarkResidual)      (None, 20, 20, 512)  2625536     DarkRes_5_2[0][0]                
__________________________________________________________________________________________________
DarkRes_5_csp_connect (CSPConne (None, 20, 20, 1024) 1316864     DarkRes_5_3[0][0]                
                                                                 DarkRes_5_csp_down[0][1]         
==================================================================================================
Total params: 26,631,008
Trainable params: 26,596,192
Non-trainable params: 34,816
__________________________________________________________________________________________________
{'embed_spp': False, 'use_fpn': True, 'max_level_process_len': None, 'csp_stack': 5, 'fpn_depth': 5, 'path_process_len': 6, 'activation': 'mish', 'subdivisions': 1, 'use_spatial_attention': False, 'use_sync_bn': True, 'norm_momentum': 0.97, 'norm_epsilon': 0.0001, 'kernel_regularizer': <tensorflow.python.keras.regularizers.L2 object at 0x7f29ce2bd2e0>}
[[12.0, 16.0], [19.0, 36.0], [40.0, 28.0], [36.0, 75.0], [76.0, 55.0], [72.0, 146.0], [142.0, 110.0], [192.0, 243.0], [459.0, 401.0]]
{'3': 1.0, '4': 1.0, '5': 1.0, 'all': None}
{'3': 1.0, '4': 1.0, '5': 1.0, 'all': None}
{'3': 'ciou', '4': 'ciou', '5': 'ciou', 'all': 'ciou'}
{'3': 'ciou', '4': 'ciou', '5': 'ciou', 'all': 'ciou'}
{'3': inf, '4': inf, '5': inf, 'all': None}
{'3': inf, '4': inf, '5': inf, 'all': None}
{'3': True, '4': True, '5': True, 'all': True}
{'3': True, '4': True, '5': True, 'all': True}
{'3': 0.75, '4': 0.75, '5': 0.75, 'all': 0.05}
{'3': 0.05, '4': 0.05, '5': 0.05, 'all': 0.05}
{'3': 1.0, '4': 1.0, '5': 1.0, 'all': 0.5}[[0 0 0 0 -15.0023775 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804]
 [0 0 0 0 -15.0023775 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804]
 [0 0 0 0 -15.0023775 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804]]
[[0 0 0 0 -16.3886719 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804]
 [0 0 0 0 -16.3886719 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804]
 [0 0 0 0 -16.3886719 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804]]
[[0 0 0 0 -17.7749672 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804]
 [0 0 0 0 -17.7749672 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804]
 [0 0 0 0 -17.7749672 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804 -4.8804]]
WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example
  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)
W0716 22:30:51.990473 139826756593472 loss_scale_optimizer.py:1039] tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example
  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)
I0716 22:30:52.283870 139826756593472 dataset_builder.py:858] No config specified, defaulting to first: coco/2014
I0716 22:30:52.284564 139826756593472 dataset_info.py:365] Load dataset info from /media/vbanna/DATA_SHARE/CV/datasets/tensorflow/coco/2014/1.1.0
I0716 22:30:52.286685 139826756593472 dataset_info.py:422] Field info.description from disk and from code do not match. Keeping the one from code.
I0716 22:30:52.286783 139826756593472 dataset_info.py:422] Field info.config_description from disk and from code do not match. Keeping the one from code.
I0716 22:30:52.286906 139826756593472 dataset_info.py:422] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0716 22:30:52.287021 139826756593472 dataset_builder.py:351] Reusing dataset coco (/media/vbanna/DATA_SHARE/CV/datasets/tensorflow/coco/2014/1.1.0)
I0716 22:30:52.287092 139826756593472 logging_logger.py:33] Constructing tf.data.Dataset coco for split validation, from /media/vbanna/DATA_SHARE/CV/datasets/tensorflow/coco/2014/1.1.0
I0716 22:30:56.947935 139826756593472 controller.py:362] restoring or initializing model...

{'3': 0.5, '4': 0.5, '5': 0.5, 'all': 0.5}
{'3': 4.0, '4': 1.0, '5': 0.4, 'all': None}
{'3': 4.0, '4': 1.0, '5': 0.4, 'all': None}
{'3': 0.7, '4': 0.7, '5': 0.7, 'all': None}
{'3': 0.7, '4': 0.7, '5': 0.7, 'all': None}
{'3': 0.0, '4': 0.0, '5': 0.0, 'all': 1.0}
{'3': 1.0, '4': 1.0, '5': 1.0, 'all': 1.0}
Model: "YoloDecoder"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 80, 80, 256) 0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None, 40, 40, 512) 0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            [(None, 20, 20, 1024 0                                            
__________________________________________________________________________________________________
yolo_fpn (YoloFPN)              {'5': (None, 20, 20, 9626112     input_2[0][0]                    
                                                                 input_3[0][0]                    
                                                                 input_4[0][0]                    
__________________________________________________________________________________________________
yolo_pan (YoloPAN)              {'3': (None, 80, 80, 16271360    yolo_fpn[0][0]                   
                                                                 yolo_fpn[0][1]                   
                                                                 yolo_fpn[0][2]                   
==================================================================================================
Total params: 25,897,472
Trainable params: 25,867,520
Non-trainable params: 29,952
__________________________________________________________________________________________________
Model: "yolo"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
altered_cspdarknet53 (Darkne OrderedDict([('3', (None, 26631008  
_________________________________________________________________
YoloDecoder (YoloDecoder)    {'3': (None, 80, 80, 256) 25897472  
_________________________________________________________________
yolo_layer (YoloLayer)       multiple                  0         
_________________________________________________________________
yolo_head (YoloHead)         multiple                  457725    
=================================================================
Total params: 52,986,205
Trainable params: 52,921,437
Non-trainable params: 64,768
_________________________________________________________________
defaultdict(<class 'list'>, {'3': ['box_loss', 'class_loss', 'conf_loss', 'recall50', 'precision50', 'avg_iou', 'avg_obj'], '4': ['box_loss', 'class_loss', 'conf_loss', 'recall50', 'precision50', 'avg_iou', 'avg_obj'], '5': ['box_loss', 'class_loss', 'conf_loss', 'recall50', 'precision50', 'avg_iou', 'avg_obj'], 'global': ['total_loss', 'total_box', 'total_class', 'total_conf']})
[[12.0, 16.0], [19.0, 36.0], [40.0, 28.0], [36.0, 75.0], [76.0, 55.0], [72.0, 146.0], [142.0, 110.0], [192.0, 243.0], [459.0, 401.0]]
<PrefetchDataset shapes: ((1, 640, 640, 3), {source_id: (1,), bbox: (1, 300, 4), classes: (1, 300), area: (1, 300), is_crowd: (1, 300), best_anchors: (1, 300, 9), best_iou_match: (1, 300, 9), width: (1,), height: (1,), info: (1, 4, 2), num_detections: (1,), upds: {3: (1, 2100, 8), 4: (1, 1800, 8), 5: (1, 1500, 8)}, inds: {3: (1, 2100, 3), 4: (1, 1800, 3), 5: (1, 1500, 3)}, true_conf: {3: (1, 80, 80, 3, 1), 4: (1, 40, 40, 3, 1), 5: (1, 20, 20, 3, 1)}}), types: (tf.float32, {source_id: tf.int64, bbox: tf.float32, classes: tf.float32, area: tf.float32, is_crowd: tf.int32, best_anchors: tf.float32, best_iou_match: tf.float32, width: tf.int32, height: tf.int32, info: tf.float32, num_detections: tf.int32, upds: {3: tf.float32, 4: tf.float32, 5: tf.float32}, inds: {3: tf.int32, 4: tf.int32, 5: tf.int32}, true_conf: {3: tf.float32, 4: tf.float32, 5: tf.float32}})>
restoring or initializing model...
64 seen
major: 0
minor: 2
revision: 5
iseen: 0
{'_type': 'net', 'batch': 64, 'subdivisions': 8, 'width': 512, 'height': 512, 'channels': 3, 'momentum': 0.949, 'decay': 0.0005, 'angle': 0, 'saturation': 1.5, 'exposure': 1.5, 'hue': 0.1, 'learning_rate': 0.00261, 'burn_in': 1000, 'max_batches': 500500, 'policy': 'steps', 'steps': (400000, 450000), 'scales': (0.1, 0.1), 'mosaic': 1}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 32, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 32, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': -2}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 64, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -10)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': -2}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -28)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': -2}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -28)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 1024, 'size': 3, 'stride': 2, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': -2}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 3, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'shortcut', 'from': -3, 'activation': 'linear'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -16)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 1024, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': -2}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'maxpool', 'stride': 1, 'size': 5}
{'_type': 'route', 'layers': -2}
{'_type': 'maxpool', 'stride': 1, 'size': 9}
{'_type': 'route', 'layers': -4}
{'_type': 'maxpool', 'stride': 1, 'size': 13}
{'_type': 'route', 'layers': (-1, -3, -5, -6)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -13)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'upsample', 'stride': 2}
{'_type': 'route', 'layers': 79}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -3)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': -2}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 256, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 256, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -6)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'upsample', 'stride': 2}
{'_type': 'route', 'layers': 48}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -3)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': -2}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 128, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 128, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -6)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 128, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 256, 'activation': 'mish'}
{'_type': 'convolutional', 'size': 1, 'stride': 1, 'pad': 1, 'filters': 255, 'activation': 'linear'}
{'_type': 'yolo', 'mask': (0, 1, 2), 'anchors': [(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], 'classes': 80, 'num': 9, 'jitter': 0.3, 'ignore_thresh': 0.7, 'truth_thresh': 1, 'random': 1, 'scale_x_y': 1.05, 'iou_thresh': 0.213, 'cls_normalizer': 1.0, 'iou_normalizer': 0.07, 'iou_loss': 'ciou', 'nms_kind': 'greedynms', 'beta_nms': 0.6}
{'_type': 'route', 'layers': -4}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 2, 'pad': 1, 'filters': 256, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -20)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': -2}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 256, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 256, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -6)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 256, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'mish'}
{'_type': 'convolutional', 'size': 1, 'stride': 1, 'pad': 1, 'filters': 255, 'activation': 'linear'}
{'_type': 'yolo', 'mask': (3, 4, 5), 'anchors': [(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], 'classes': 80, 'num': 9, 'jitter': 0.3, 'ignore_thresh': 0.7, 'truth_thresh': 1, 'random': 1, 'scale_x_y': 1.05, 'iou_thresh': 0.213, 'cls_normalizer': 1.0, 'iou_normalizer': 0.07, 'iou_loss': 'ciou', 'nms_kind': 'greedynms', 'beta_nms': 0.6}
{'_type': 'route', 'layers': -4}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 2, 'pad': 1, 'filters': 512, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -49)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'route', 'layers': -2}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 512, 'activation': 'mish'}
{'_type': 'route', 'layers': (-1, -6)}
{'_type': 'convolutional', 'batch_normalize': 1, 'filters': 512, 'size': 1, 'stride': 1, 'pad': 1, 'activation': 'mish'}
{'_type': 'convolutional', 'batch_normalize': 1, 'size': 3, 'stride': 1, 'pad': 1, 'filters': 1024, 'activation': 'mish'}
{'_type': 'convolutional', 'size': 1, 'stride': 1, 'pad': 1, 'filters': 255, 'activation': 'linear'}
{'_type': 'yolo', 'mask': (6, 7, 8), 'anchors': [(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], 'classes': 80, 'num': 9, 'jitter': 0.3, 'ignore_thresh': 0.7, 'truth_thresh': 1, 'random': 1, 'scale_x_y': 1.05, 'iou_thresh': 0.213, 'cls_normalizer': 1.0, 'iou_normalizer': 0.07, 'iou_loss': 'ciou', 'nms_kind': 'greedynms', 'beta_nms': 0.6}
full net: 
512 512 3	convCFG(_type='convolutional', w=512, h=512, c=3, size=3, stride=1, pad=1, filters=32)
512 512 32	convCFG(_type='convolutional', w=512, h=512, c=32, size=3, stride=2, pad=1, filters=64)
256 256 64	convCFG(_type='convolutional', w=256, h=256, c=64, size=1, stride=1, pad=0, filters=32)
256 256 32	convCFG(_type='convolutional', w=256, h=256, c=32, size=3, stride=1, pad=1, filters=64)
256 256 64	shortcutCFG(_type='shortcut', w=256, h=256, c=64, _from=(-3,), activation='linear')
256 256 64	convCFG(_type='convolutional', w=256, h=256, c=64, size=3, stride=2, pad=1, filters=128)
128 128 128	convCFG(_type='convolutional', w=128, h=128, c=128, size=1, stride=1, pad=0, filters=64)
128 128 128	routeCFG(_type='route', w=128, h=128, c=128, layers=(-2,))
128 128 128	convCFG(_type='convolutional', w=128, h=128, c=128, size=1, stride=1, pad=0, filters=64)
128 128 64	convCFG(_type='convolutional', w=128, h=128, c=64, size=1, stride=1, pad=0, filters=64)
128 128 64	convCFG(_type='convolutional', w=128, h=128, c=64, size=3, stride=1, pad=1, filters=64)
128 128 64	shortcutCFG(_type='shortcut', w=128, h=128, c=64, _from=(-3,), activation='linear')
128 128 64	convCFG(_type='convolutional', w=128, h=128, c=64, size=1, stride=1, pad=0, filters=64)
128 128 64	convCFG(_type='convolutional', w=128, h=128, c=64, size=3, stride=1, pad=1, filters=64)
128 128 64	shortcutCFG(_type='shortcut', w=128, h=128, c=64, _from=(-3,), activation='linear')
128 128 64	convCFG(_type='convolutional', w=128, h=128, c=64, size=1, stride=1, pad=0, filters=64)
128 128 128	routeCFG(_type='route', w=128, h=128, c=128, layers=(-1, -10))
128 128 128	convCFG(_type='convolutional', w=128, h=128, c=128, size=1, stride=1, pad=0, filters=128)
128 128 128	convCFG(_type='convolutional', w=128, h=128, c=128, size=3, stride=2, pad=1, filters=256)
64 64 256	convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)
64 64 256	routeCFG(_type='route', w=64, h=64, c=256, layers=(-2,))
64 64 256	convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 128	shortcutCFG(_type='shortcut', w=64, h=64, c=128, _from=(-3,), activation='linear')
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 128	shortcutCFG(_type='shortcut', w=64, h=64, c=128, _from=(-3,), activation='linear')
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 128	shortcutCFG(_type='shortcut', w=64, h=64, c=128, _from=(-3,), activation='linear')
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 128	shortcutCFG(_type='shortcut', w=64, h=64, c=128, _from=(-3,), activation='linear')
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 128	shortcutCFG(_type='shortcut', w=64, h=64, c=128, _from=(-3,), activation='linear')
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 128	shortcutCFG(_type='shortcut', w=64, h=64, c=128, _from=(-3,), activation='linear')
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 128	shortcutCFG(_type='shortcut', w=64, h=64, c=128, _from=(-3,), activation='linear')
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 128	shortcutCFG(_type='shortcut', w=64, h=64, c=128, _from=(-3,), activation='linear')
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 256	routeCFG(_type='route', w=64, h=64, c=256, layers=(-1, -28))
64 64 256	convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=256)
64 64 256	convCFG(_type='convolutional', w=64, h=64, c=256, size=3, stride=2, pad=1, filters=512)
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
32 32 512	routeCFG(_type='route', w=32, h=32, c=512, layers=(-2,))
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	shortcutCFG(_type='shortcut', w=32, h=32, c=256, _from=(-3,), activation='linear')
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	shortcutCFG(_type='shortcut', w=32, h=32, c=256, _from=(-3,), activation='linear')
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	shortcutCFG(_type='shortcut', w=32, h=32, c=256, _from=(-3,), activation='linear')
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	shortcutCFG(_type='shortcut', w=32, h=32, c=256, _from=(-3,), activation='linear')
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	shortcutCFG(_type='shortcut', w=32, h=32, c=256, _from=(-3,), activation='linear')
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	shortcutCFG(_type='shortcut', w=32, h=32, c=256, _from=(-3,), activation='linear')
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	shortcutCFG(_type='shortcut', w=32, h=32, c=256, _from=(-3,), activation='linear')
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	shortcutCFG(_type='shortcut', w=32, h=32, c=256, _from=(-3,), activation='linear')
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 512	routeCFG(_type='route', w=32, h=32, c=512, layers=(-1, -28))
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=512)
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=3, stride=2, pad=1, filters=1024)
16 16 1024	convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
16 16 1024	routeCFG(_type='route', w=16, h=16, c=1024, layers=(-2,))
16 16 1024	convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
16 16 512	shortcutCFG(_type='shortcut', w=16, h=16, c=512, _from=(-3,), activation='linear')
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
16 16 512	shortcutCFG(_type='shortcut', w=16, h=16, c=512, _from=(-3,), activation='linear')
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
16 16 512	shortcutCFG(_type='shortcut', w=16, h=16, c=512, _from=(-3,), activation='linear')
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
16 16 512	shortcutCFG(_type='shortcut', w=16, h=16, c=512, _from=(-3,), activation='linear')
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
16 16 1024	routeCFG(_type='route', w=16, h=16, c=1024, layers=(-1, -16))
16 16 1024	convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=1024)
16 16 1024	convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
16 16 1024	routeCFG(_type='route', w=16, h=16, c=1024, layers=(-2,))
16 16 1024	convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
16 16 512	maxpoolCFG(_type='maxpool', w=16, h=16, c=512, stride=1, size=5)
16 16 512	routeCFG(_type='route', w=16, h=16, c=512, layers=(-2,))
16 16 512	maxpoolCFG(_type='maxpool', w=16, h=16, c=512, stride=1, size=9)
16 16 512	routeCFG(_type='route', w=16, h=16, c=512, layers=(-4,))
16 16 512	maxpoolCFG(_type='maxpool', w=16, h=16, c=512, stride=1, size=13)
16 16 2048	routeCFG(_type='route', w=16, h=16, c=2048, layers=(-1, -3, -5, -6))
16 16 2048	convCFG(_type='convolutional', w=16, h=16, c=2048, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
16 16 1024	routeCFG(_type='route', w=16, h=16, c=1024, layers=(-1, -13))
16 16 1024	convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=256)
16 16 256	upsampleCFG(_type='upsample', w=16, h=16, c=256, stride=2)
32 32 512	routeCFG(_type='route', w=32, h=32, c=512, layers=(79,))
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
32 32 512	routeCFG(_type='route', w=32, h=32, c=512, layers=(-1, -3))
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	routeCFG(_type='route', w=32, h=32, c=256, layers=(-2,))
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 512	routeCFG(_type='route', w=32, h=32, c=512, layers=(-1, -6))
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=128)
32 32 128	upsampleCFG(_type='upsample', w=32, h=32, c=128, stride=2)
64 64 256	routeCFG(_type='route', w=64, h=64, c=256, layers=(48,))
64 64 256	convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)
64 64 256	routeCFG(_type='route', w=64, h=64, c=256, layers=(-1, -3))
64 64 256	convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	routeCFG(_type='route', w=64, h=64, c=128, layers=(-2,))
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
64 64 256	routeCFG(_type='route', w=64, h=64, c=256, layers=(-1, -6))
64 64 256	convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=256)
64 64 256	convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=255)
64 64 255	yoloCFG(_type='yolo', w=64, h=64, c=255, mask=(0, 1, 2), anchors=[(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], scale_x_y=1)
64 64 128	routeCFG(_type='route', w=64, h=64, c=128, layers=(-4,))
64 64 128	convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=2, pad=1, filters=256)
32 32 512	routeCFG(_type='route', w=32, h=32, c=512, layers=(-1, -20))
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	routeCFG(_type='route', w=32, h=32, c=256, layers=(-2,))
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
32 32 512	routeCFG(_type='route', w=32, h=32, c=512, layers=(-1, -6))
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=512)
32 32 512	convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=255)
32 32 255	yoloCFG(_type='yolo', w=32, h=32, c=255, mask=(3, 4, 5), anchors=[(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], scale_x_y=1)
32 32 256	routeCFG(_type='route', w=32, h=32, c=256, layers=(-4,))
32 32 256	convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=2, pad=1, filters=512)
16 16 1024	routeCFG(_type='route', w=16, h=16, c=1024, layers=(-1, -49))
16 16 1024	convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
16 16 512	routeCFG(_type='route', w=16, h=16, c=512, layers=(-2,))
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
16 16 1024	routeCFG(_type='route', w=16, h=16, c=1024, layers=(-1, -6))
16 16 1024	convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
16 16 512	convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=1024)
16 16 1024	convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=255)
16 16 255	yoloCFG(_type='yolo', w=16, h=16, c=255, mask=(6, 7, 8), anchors=[(12, 16), (19, 36), (40, 28), (36, 75), (76, 55), (72, 146), (142, 110), (192, 243), (459, 401)], scale_x_y=1)
bytes_read: 211944840, original_size: 211944840, final_position: 211944840
ConvBN_0_0 convCFG(_type='convolutional', w=512, h=512, c=3, size=3, stride=1, pad=1, filters=32)
conv_bn convCFG(_type='convolutional', w=512, h=512, c=32, size=3, stride=2, pad=1, filters=64)
conv_bn_1 convCFG(_type='convolutional', w=256, h=256, c=64, size=1, stride=1, pad=0, filters=32)
conv_bn_2 convCFG(_type='convolutional', w=256, h=256, c=32, size=3, stride=1, pad=1, filters=64)
conv_bn convCFG(_type='convolutional', w=256, h=256, c=64, size=3, stride=2, pad=1, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=128, h=128, c=128, size=1, stride=1, pad=0, filters=64)
conv_bn_2 convCFG(_type='convolutional', w=128, h=128, c=128, size=1, stride=1, pad=0, filters=64)
conv_bn convCFG(_type='convolutional', w=128, h=128, c=64, size=1, stride=1, pad=0, filters=64)
conv_bn_1 convCFG(_type='convolutional', w=128, h=128, c=64, size=3, stride=1, pad=1, filters=64)
conv_bn convCFG(_type='convolutional', w=128, h=128, c=64, size=1, stride=1, pad=0, filters=64)
conv_bn_1 convCFG(_type='convolutional', w=128, h=128, c=64, size=3, stride=1, pad=1, filters=64)
conv_bn convCFG(_type='convolutional', w=128, h=128, c=64, size=1, stride=1, pad=0, filters=64)
conv_bn_1 convCFG(_type='convolutional', w=128, h=128, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn convCFG(_type='convolutional', w=128, h=128, c=128, size=3, stride=2, pad=1, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)
conv_bn_2 convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_1 convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn convCFG(_type='convolutional', w=64, h=64, c=256, size=3, stride=2, pad=1, filters=512)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
conv_bn_2 convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_1 convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn convCFG(_type='convolutional', w=32, h=32, c=512, size=3, stride=2, pad=1, filters=1024)
conv_bn_1 convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
conv_bn_2 convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
conv_bn convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn_1 convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
conv_bn convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn_1 convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
conv_bn convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn_1 convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
conv_bn convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn_1 convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
conv_bn convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn_1 convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=1024)
private__identity_route
dark_route_process_1
<yolo.modeling.layers.nn_blocks.DarkRouteProcess object at 0x7f29cd330430>
rout conv
rout conv
conv
conv
conv
conv
dark_route_process
<yolo.modeling.layers.nn_blocks.DarkRouteProcess object at 0x7f29cd334e50>
rout conv
rout conv
conv
conv
conv
conv
conv
path_aggregation_block_1
<yolo.modeling.layers.nn_blocks.PathAggregationBlock object at 0x7f29cd2fd4c0>
path conv
path conv
path conv
path_aggregation_block
<yolo.modeling.layers.nn_blocks.PathAggregationBlock object at 0x7f29cd2ebcd0>
path conv
path conv
path conv
csp_route_1
conv_bn_10
conv_bn_11
conv_bn_12
csp_connect_1
conv_bn_13
conv_bn_14
conv_bn_15
conv2d_10
sync_batch_normalization_10
conv2d_11
sync_batch_normalization_11
conv2d_12
sync_batch_normalization_12
conv2d_13
sync_batch_normalization_13
conv2d_14
sync_batch_normalization_14
concatenate_3
conv2d_15
sync_batch_normalization_15
csp_route
conv_bn
conv_bn_1
spp
conv_bn_2
conv_bn_3
csp_connect
conv_bn_4
conv_bn_5
conv_bn_6
conv2d
sync_batch_normalization
conv2d_1
sync_batch_normalization_1
conv2d_2
sync_batch_normalization_2
conv2d_3
sync_batch_normalization_3
max_pooling2d
max_pooling2d_1
max_pooling2d_2
conv2d_4
sync_batch_normalization_4
conv2d_5
sync_batch_normalization_5
concatenate_1
conv2d_6
sync_batch_normalization_6
concatenate_4
conv_bn_16
conv_bn_17
conv_bn_18
conv2d_16
sync_batch_normalization_16
conv2d_17
sync_batch_normalization_17
conv2d_18
sync_batch_normalization_18
concatenate_2
conv_bn_7
conv_bn_8
conv_bn_9
conv2d_7
sync_batch_normalization_7
conv2d_8
sync_batch_normalization_8
conv2d_9
sync_batch_normalization_9
19 44
conv_bn_5 512.0 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
conv_bn_6 512.0 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
conv_bn 512.0 (3, 3) convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
conv_bn_1 512.0 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn_2 512.0 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=2048, size=1, stride=1, pad=0, filters=512)
conv_bn_3 512.0 (3, 3) convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
conv_bn_4 512.0 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
conv_bn_7 256.0 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=256)
conv_bn_8 256.0 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
conv_bn_9 256.0 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
conv_bn_14 256.0 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_15 256.0 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_10 256.0 (3, 3) convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn_11 256.0 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_12 256.0 (3, 3) convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn_13 256.0 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
conv_bn_16 128.0 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=128)
conv_bn_17 128.0 (1, 1) convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)
conv_bn_18 128.0 (1, 1) convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)I0716 22:30:57.814331 139826756593472 controller.py:368] initialized model.
I0716 22:30:57.814488 139826756593472 train_lib.py:96] Starts to execute mode: train
I0716 22:30:57.814958 139826756593472 controller.py:211] train | step:      0 | training until step 100...
2021-07-16 22:30:58.426696: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-07-16 22:30:58.446699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3499910000 Hz
2021-07-16 22:31:29.615367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
0
0
24
2021-07-16 22:31:30.865441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-07-16 22:31:31.223728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
30290 -0.14565514 0.0101987105 0.00983406417 0.00720211491 0.0272348896
93
126
33
580720 -0.260915756 0.0454748981 0.0949802101 0.025371382 0.165826485
0
0
18
120398 -1.07539463 0.0036157039 0.00697321258 0.00086830731 0.0114572234
0
12
24
375376 -2.08987188 0.00669197 0.00877392758 0.000445221725 0.0159111191
93
12
6
365485 -1.45324278 0.0338479839 0.0585592762 0.00992283504 0.102330089
3
9
3
16241 0.58146131 0.00977969 0.0015296879 0.000647580368 0.0119569572
72
93
45
212112 -2.4488306 0.0294013508 0.0697088242 0.0133394618 0.112449616
0
12
15
491294 5.97075653 0.012684226 0.00849578902 0.000962817809 0.022142835
93
96
87
70478 -1.35363686 0.0497006848 0.0939756632 0.0135524273 0.157228753
0
0
15
415823 -2.86276865 0.00327992416 0.00916747 0.000303205044 0.0127505995
93
39
3
259452 -1.30399442 0.0403734557 0.0452295579 0.00727119297 0.0928742
96
120
45
475182 0.473791629 0.04935937 0.133273214 0.00264583249 0.185278416
0
12
21
212198 -3.12247324 0.00644198386 0.0069671832 0.000827389653 0.0142365564
0
0
6
75162 5.26896906 0.00178987684 0.00160868699 0.000164518482 0.00356308231, this gradient is way bigger!
15
33
27
319830 2.19037867 0.0372251756 0.0404636636 0.00367482356 0.0813636631
6
33
36
160260 -2.79904795 0.0161521919 0.0397074334 0.000486595 0.0563462153
6
30
36
116261 -0.881833911 0.00922458526 0.0208146609 0.00195610942 0.0319953561
0
18
39
224557 1.57092488 0.00985286757 0.0263217241 0.00982328691 0.0459978804
120
36
15
402248 2.97587442 0.0393328369 0.0518517829 0.0212968849 0.112481505
0
0
6
259614 -4.08918524 0.00259324675 0.00287564541 0.000158841431 0.00562773366
6
21
18
118921 -0.242582336 0.0561752878 0.0129935089 0.000766729412 0.069935523, gradeint is really different
0
3
6
552656 1.60716319 0.00395632535 0.00338495336 0.000674859853 0.00801613834
0
9
9
316000 -2.76492929 0.0199858677 0.00729727652 0.000429859967 0.0277130045
132
96
51
46847 0.249620378 0.0472084694 0.103100494 0.00586456805 0.156173527 gradient is very different
9
36
30
220819 0.439644843 0.012531898 0.0214525983 0.000747584 0.034732081 gradeint very different loss is not 
12
63
33
372819 -1.40399265 0.0285938922 0.0229890011 0.0347144753 0.0862973779
6
18
9
109537 -5.8866744 0.0163101237 0.00822175574 0.000712896173 0.0252447762
0
6
18
369667 4.34638262 0.00600179378 0.00618248759 0.000286640628 0.0124709215
3
9
24
238147 1.27583826 0.0222882982 0.0205548313 0.00278419047 0.045627322, gradient very different but loss is not 
9
9
3
320370 5.52797794 0.0241632313 0.00390850753 0.000644435 0.0287161749, gradient very different, loss is too
0
0
0
317130 0.0103094419 0 0.000449426967 0 0.000449426967
0
12
21
464018 0.906339645 0.00902818888 0.0228273906 0.0018345745 0.0336901546, gradient is very different
9
21
15
296759 4.24366426 0.0228110347 0.0352317542 0.00156794838 0.0596107394
9
6
9
52017 0.0109140854 0.0531214587 0.00770037668 0.000427420484 0.0612492599
0
0
15
33372 1.49253917 0.00437197834 0.0119099598 0.00323933945 0.0195212774
0
9
15
80671 1.59678102 0.0182848647 0.00961889 0.000420777971 0.0283245314
30
33
24
259335 1.02185214 0.0273504891 0.0170616526 0.0152847897 0.0596969314, gradient is verry different, loss is not
24
24
9
184205 -0.586798251 0.0182792973 0.0275091641 0.0284822937 0.0742707551, gradient is verry different, loss is not
3
3
15
459887 4.53225422 0.0433046259 0.0143605201 0.0551053137 0.112770453
72
63
27
389753 2.28445768 0.0414117947 0.0521539114 0.00563017605 0.0991958752
45
45
24
197279 0.980173111 0.0249498319 0.0282451548 0.00114080834 0.0543358
57
24
9
224554 -1.72578096 0.0434037596 0.023589436 0.00145897549 0.068452172
135
123
60
246014 1.57098269 0.0498691313 0.144248098 0.00796202198 0.202079266
3
9
12
486162 1.12387991 0.0131736267 0.0110437684 0.00839367323 0.0326110683
6
39
51
124429 0.259165525 0.0314061046 0.0664114 0.027261937 0.125079438, gradient is very different but loss is not 
3
18
21
234807 0.808490455 0.00656899391 0.00474862102 0.000767267251 0.0120848827
9
18
21
294908 0.867093205 0.011504625 0.0111005753 0.000759042508 0.0233642422, gradient is very different but loss is not 
36
54
42
192406 -1.26232338 0.0435371548 0.076408729 0.00485350704 0.124799386
0
3
15
574411 -2.73770261 0.0261260457 0.00606468553 0.00720912591 0.0393998586, gradient different but loss is not that different
0
3
21
223241 -2.19227552 0.0409541801 0.0215506554 0.0306876376 0.0931924731
0
3
18
209728 0.114513122 0.00599964289 0.00485409843 0.000323013839 0.0111767557, gradient is very different but loss is not 
129
93
18
48133 -4.00494814 0.0444185436 0.0908978656 0.00835503358 0.143671438
0
3
15
542388 1.15606284 0.0069779153 0.0136460392 0.000378579221 0.0210025329
0
0
9
377738 2.73907065 0.0206483863 0.018380424 0.0349588022 0.0739876106
0
0
9
173235 5.18403292 0.00359471561 0.012687237 0.000379074452 0.0166610274
51
90
78
517399 -0.55322206 0.0256713573 0.0644853264 0.0223891363 0.112545826
12
33
48
394050 1.9374032 0.029692132 0.0684813559 0.00739820488 0.105571695
0
15
24
101919 4.54483223 0.00867088884 0.0131949987 0.000393430586 0.0222593192
6
15
15
155192 -0.69476229 0.0141918706 0.00662624743 0.000392454851 0.0212105736, gradeints_different but loss is not 
72
36
18
226097 0.693813801 0.0362318 0.0385313742 0.0165681653 0.0913313404
99
87
30
355441 0.729052842 0.024818508 0.0443236195 0.00140107772 0.0705432
6
6
21
212605 -0.101254255 0.0413177274 0.0377537683 0.00346046593 0.0825319737
27
69
57
395904 -0.969994187 0.0176846 0.0660352111 0.0179634728 0.101683289
24
6
9
242868 1.62247968 0.033435639 0.0187644344 0.00484215422 0.0570422225
3
21
42
573206 -1.37473524 0.0338441096 0.0303289741 0.00150444871 0.0656775385
0
6
9
423396 -3.82164335 0.0184023418 0.00351128122 0.000412981695 0.0223266054
24
36
18
293175 -1.47627354 0.0300445855 0.0391499214 0.00716879312 0.0763633
0
12
33
276146 0.486271024 0.0054516769 0.0229701214 0.000564081827 0.0289858803, gradeint is very different loss is same
9
42
51
344548 0.778208375 0.0182522088 0.0249935556 0.000947721768 0.0441934876
0
9
9
260020 -0.220943108 0.00369362906 0.00128789712 0.00063543173 0.00561695825, gradeint is very different loss is too
9
18
9
406744 -4.27956867 0.041849833 0.00908059 0.000904999557 0.0518354215
9
12
9
467468 0.36229533 0.0213897731 0.0128670381 0.0040474874 0.0383043, gradeint is very different loss is same
12
18
6
233140 0.193355888 0.00967531931 0.00794974063 0.00112238096 0.0187474415
3
9
9
473121 3.71803522 0.0218220074 0.010823953 0.000516796077 0.033162754, gradeint is very different loss is same
55
156
117
27642 0.151956975 0.0356212109 0.143129081 0.00497481972 0.183725119
12
21
18
30465 -0.0996461958 0.0154341226 0.0157605708 0.0248046294 0.05599932, gradeint is very different loss is same
12
18
6
283441 3.69909334 0.0127411652 0.0169050694 0.00167296117 0.0313191935, gradeint is very different loss is same
27
33
21
466346 -0.217573598 0.0265248362 0.0333505459 0.000696881383 0.0605722629
3
18
9
275058 1.67966425 0.0178710278 0.00738151465 0.000493560045 0.0257461034
6
27
27
322848 -3.20585775 0.0230023582 0.0305374041 0.00110623671 0.054646
27
60
45
253770 -0.653010309 0.0280721728 0.0549000278 0.000901072228 0.0838732645
12
78
54
239148 1.3080343 0.0277554188 0.0361176021 0.000586675713 0.0644597
45
96
60
172595 0.309965253 0.0374476127 0.0725810304 0.0244029388 0.134431601, gradeint is different but loss is smilar
0
9
15
69959 -1.16579962 0.00398328761 0.00879045948 0.000576994265 0.0133507401, gradeint is different but loss is same
0
3
18
537907 2.84632826 0.010100631 0.0138760088 0.00677158544 0.0307482257, gradeint is different and loss is different
6
27
21
245049 -1.11769283 0.0131200328 0.00955643319 0.00068905286 0.0233655199
33
21
9
250571 5.24694633 0.0302315149 0.0229247883 0.00198833784 0.0551446453
30
56
68
522665 -0.361827046 0.0333968587 0.0835218 0.00421826262 0.121136904, gradeint is different but loss is smilar
0
9
15
232453 -0.152915299 0.0148989409 0.0101508219 0.00121787773 0.0262676403
72
114
57
237324 0.364521831 0.0401966795 0.0849178955 0.00979502592 0.1349096
0
6
24
180366 1.16043329 0.00925061386 0.0179053601 0.00779397786 0.0349499509
0
0
18
432906 3.76267672 0.00515208766 0.0149084227 0.00296708196 0.0230275914
0
3
15
113579 3.93474436 0.00816220697 0.00670832535 0.000384404906 0.015254938
60
141
105
113720 1.96548152 0.02624554 0.126530662 0.0121816499 0.164957851
3
24
28
463611 1.54200923 0.0157753117 0.0166820474 0.00336115761 0.0358185172, gradeitn is different loss is slightly different
3
9
3
298137 0.502034187 0.00600758102 0.00105744984 0.00074273732 0.00780776795, gradeitn is different loss is very different
12
18
6
485773 7.9280324 0.0135073885 0.00462271646 0.000613374694 0.0187434796
0
0
15
443818 1.93265676 0.00376608595 0.0133748213 0.0243941881 0.0415350944, gradeitn is different loss is slightly different
18
12
6
18149 3.84782743 0.039007064 0.0103405751 0.0280893296 0.0774369687, gradeitn is very different loss is slightly different
15
36
30
494846 0.398177147 0.0254329275 0.0299659818 0.00103614491 0.0564350598, gradeitn is very different loss is same
I0716 22:31:42.737287 139826756593472 controller.py:425] train | step:    100 | steps/sec:    2.2 | output: 
    {'3': {'avg_iou': 0.51812667,
           'avg_obj': 0.21107423,
           'box_loss': 0.0076246555,
           'class_loss': 0.0019472889,
           'conf_loss': 0.009901892,
           'precision50': 0.38497284,
           'recall50': 0.2074002},
     '4': {'avg_iou': 0.735084,
           'avg_obj': 0.4179064,
           'box_loss': 0.007902745,
           'class_loss': 0.0017916779,
           'conf_loss': 0.010378837,
           'precision50': 0.634275,
           'recall50': 0.43355998},
     '5': {'avg_iou': 0.85675955,
           'avg_obj': 0.58891726,
           'box_loss': 0.0067143673,
           'class_loss': 0.003006261,
           'conf_loss': 0.010534806,
           'precision50': 0.80783325,
           'recall50': 0.6467611},
     'global': {'total_box': 0.022241766,
                'total_class': 0.0067452285,
                'total_conf': 0.030815544,
                'total_loss': 0.059802543},
     'learning_rate': 0.0,
     'training_loss': 0.059802543}
I0716 22:31:43.730444 139826756593472 controller.py:455] saved checkpoint to ../checkpoints/sdsfsfd/ckpt-100.
I0716 22:31:43.746394 139826756593472 train_lib.py:122] Number of trainable params in model: 52.986205 Millions.

dark_route_process
<yolo.modeling.layers.nn_blocks.DarkRouteProcess object at 0x7f29ccfcf430>
rout conv
rout conv
conv
conv
conv
conv
conv
dark_route_process_1
<yolo.modeling.layers.nn_blocks.DarkRouteProcess object at 0x7f29ccfcf6a0>
rout conv
rout conv
conv
conv
conv
conv
conv
dark_route_process_2
<yolo.modeling.layers.nn_blocks.DarkRouteProcess object at 0x7f29cd01dfd0>
rout conv
rout conv
conv
conv
conv
conv
conv
path_aggregation_block
<yolo.modeling.layers.nn_blocks.PathAggregationBlock object at 0x7f29ccfcfb80>
path conv
path conv
path_aggregation_block_1
<yolo.modeling.layers.nn_blocks.PathAggregationBlock object at 0x7f29ccfa6100>
path conv
path conv
csp_route
conv_bn
conv_bn_1
conv_bn_2
csp_connect
conv_bn_3
conv_bn_4
conv_bn_5
conv_bn_6
conv2d
sync_batch_normalization
conv2d_1
sync_batch_normalization_1
conv2d_2
sync_batch_normalization_2
conv2d_3
sync_batch_normalization_3
conv2d_4
sync_batch_normalization_4
concatenate
conv2d_5
sync_batch_normalization_5
conv2d_6
sync_batch_normalization_6
csp_route_1
conv_bn_9
conv_bn_10
conv_bn_11
csp_connect_1
conv_bn_12
conv_bn_13
conv_bn_14
conv_bn_15
conv2d_9
sync_batch_normalization_9
conv2d_10
sync_batch_normalization_10
conv2d_11
sync_batch_normalization_11
conv2d_12
sync_batch_normalization_12
conv2d_13
sync_batch_normalization_13
concatenate_2
conv2d_14
sync_batch_normalization_14
conv2d_15
sync_batch_normalization_15
csp_route_2
conv_bn_18
conv_bn_19
conv_bn_20
csp_connect_2
conv_bn_21
conv_bn_22
conv_bn_23
conv_bn_24
conv2d_18
sync_batch_normalization_18
conv2d_19
sync_batch_normalization_19
conv2d_20
sync_batch_normalization_20
conv2d_21
sync_batch_normalization_21
conv2d_22
sync_batch_normalization_22
concatenate_4
conv2d_23
sync_batch_normalization_23
conv2d_24
sync_batch_normalization_24
concatenate_1
conv_bn_7
conv_bn_8
conv2d_7
sync_batch_normalization_7
conv2d_8
sync_batch_normalization_8
concatenate_3
conv_bn_16
conv_bn_17
conv2d_16
sync_batch_normalization_16
conv2d_17
sync_batch_normalization_17
25 25
conv_bn_5 128 (1, 1) convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_6 128 (1, 1) convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn 128 (3, 3) convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn_1 128 (1, 1) convCFG(_type='convolutional', w=64, h=64, c=128, size=1, stride=1, pad=0, filters=128)
conv_bn_2 128 (3, 3) convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=128)
conv_bn_3 128 (1, 1) convCFG(_type='convolutional', w=64, h=64, c=256, size=1, stride=1, pad=0, filters=128)
conv_bn_4 256 (3, 3) convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=1, pad=1, filters=256)
conv_bn_7 256 (3, 3) convCFG(_type='convolutional', w=64, h=64, c=128, size=3, stride=2, pad=1, filters=256)
conv_bn_8 256 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
conv_bn_14 256 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_15 256 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_9 256 (3, 3) convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn_10 256 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=256, size=1, stride=1, pad=0, filters=256)
conv_bn_11 256 (3, 3) convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=256)
conv_bn_12 256 (1, 1) convCFG(_type='convolutional', w=32, h=32, c=512, size=1, stride=1, pad=0, filters=256)
conv_bn_13 512 (3, 3) convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=1, pad=1, filters=512)
conv_bn_16 512 (3, 3) convCFG(_type='convolutional', w=32, h=32, c=256, size=3, stride=2, pad=1, filters=512)
conv_bn_17 512 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
conv_bn_23 512 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn_24 512 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn_18 512 (3, 3) convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
conv_bn_19 512 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=512, size=1, stride=1, pad=0, filters=512)
conv_bn_20 512 (3, 3) convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=512)
conv_bn_21 512 (1, 1) convCFG(_type='convolutional', w=16, h=16, c=1024, size=1, stride=1, pad=0, filters=512)
conv_bn_22 1024 (3, 3) convCFG(_type='convolutional', w=16, h=16, c=512, size=3, stride=1, pad=1, filters=1024)
initialized model.
train | step:      0 | training until step 100...
train | step:    100 | steps/sec:    2.2 | output: 
    {'3': {'avg_iou': 0.51812667,
           'avg_obj': 0.21107423,
           'box_loss': 0.0076246555,
           'class_loss': 0.0019472889,
           'conf_loss': 0.009901892,
           'precision50': 0.38497284,
           'recall50': 0.2074002},
     '4': {'avg_iou': 0.735084,
           'avg_obj': 0.4179064,
           'box_loss': 0.007902745,
           'class_loss': 0.0017916779,
           'conf_loss': 0.010378837,
           'precision50': 0.634275,
           'recall50': 0.43355998},
     '5': {'avg_iou': 0.85675955,
           'avg_obj': 0.58891726,
           'box_loss': 0.0067143673,
           'class_loss': 0.003006261,
           'conf_loss': 0.010534806,
           'precision50': 0.80783325,
           'recall50': 0.6467611},
     'global': {'total_box': 0.022241766,
                'total_class': 0.0067452285,
                'total_conf': 0.030815544,
                'total_loss': 0.059802543},
     'learning_rate': 0.0,
     'training_loss': 0.059802543}
saved checkpoint to ../checkpoints/sdsfsfd/ckpt-100.
